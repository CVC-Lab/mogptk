<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>mogptk.data API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{display:none;font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mogptk.data</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L1-L1392" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import re
import copy
import inspect
import datetime
import logging
import math
import collections

import numpy as np
import pandas as pd
from scipy import signal
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pandas.plotting import register_matplotlib_converters

from .bnse import BNSE
from .serie import Serie, TransformLinear
from .plot import plot_spectrum

register_matplotlib_converters()

logger = logging.getLogger(&#39;mogptk&#39;)

def LoadFunction(f, start, end, n, var=0.0, name=&#34;&#34;, random=False):
    &#34;&#34;&#34;
    LoadFunction loads a dataset from a given function y = f(x) + Normal(0,var). It will pick `n` data points between start and end for the X axis for which `f` is being evaluated. By default the `n` points are spread equally over the interval, with `random=True` they will be picked randomly.

    The given function should take one argument X which is a list of `numpy.ndarray` of shape (n,) for every input dimension and returns an `numpy.ndarray` Y of shape (n,). If your data has only one input dimension, you can use X[0] to select the first (and only) input dimension.

    Args:
        f (function): Function taking X a list with elements of shape (n,) for each input dimension and returning shape (n,) as Y.
        start (float, list): Define start of interval.
        end (float, list): Define end of interval.
        n (int, list): Number of data points to pick between start and end.
        var (float): Variance added to the output.
        name (str): Name of data.
        random (boolean): Select points randomly between start and end.

    Returns:
        mogptk.data.Data

    Examples:
        &gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;

    if isinstance(start, np.ndarray):
        if start.ndim == 0:
            start = [start.item()]
        else:
            start = list(start)
    elif _is_iterable(start):
        start = list(start)
    else:
        start = [start]
    if isinstance(end, np.ndarray):
        if end.ndim == 0:
            end = [end.item()]
        else:
            end = list(end)
    elif _is_iterable(end):
        end = list(end)
    else:
        end = [end]
    if type(start[0]) is not type(end[0]):
        raise ValueError(&#34;start and end must be of the same type&#34;)
    if len(start) != len(end):
        raise ValueError(&#34;start and end must be of the same length&#34;)

    input_dims = len(start)
    for i in range(input_dims):
        if not _is_homogeneous_type([start[i] + end[i]]):
            raise ValueError(&#34;start and end must have elements of the same type&#34;)

        if isinstance(start[i], datetime.datetime) or isinstance(start[i], str) or isinstance(start[i], np.datetime64):
            try:
                start[i] = np.datetime64(start[i], &#39;us&#39;)
                end[i] = np.datetime64(end[i], &#39;us&#39;)
            except:
                raise ValueError(&#34;start and end must have matching number or datetime data type&#34;)
        else:
            try:
                start[i] = np.float64(start[i])
                end[i] = np.float64(end[i])
            except:
                raise ValueError(&#34;start and end must have matching number or datetime data type&#34;)

    _check_function(f, input_dims, [isinstance(start[i], np.datetime64) for i in range(input_dims)])

    if _is_iterable(n):
        n = list(n)
    else:
        n = [n] * input_dims
    if len(n) != input_dims:
        raise ValueError(&#34;n must be a scalar or a list of values for each input dimension&#34;)
    if _is_iterable(random):
        random = list(random)
    else:
        random = [random] * input_dims
    if len(random) != input_dims:
        raise ValueError(&#34;random must be a scalar or a list of values for each input dimension&#34;)

    for i in range(input_dims):
        if random[i] and isinstance(start[i], np.datetime64):
            if input_dims == 1:
                raise ValueError(&#34;cannot use random for datetime inputs for input dimension %d&#34;, (i,))
            else:
                raise ValueError(&#34;cannot use random for datetime inputs&#34;)

    x = [None] * input_dims
    for i in range(input_dims):
        if start[i] &gt;= end[i]:
            if input_dims == 1:
                raise ValueError(&#34;start must be lower than end&#34;)
            else:
                raise ValueError(&#34;start must be lower than end for input dimension %d&#34; % (i,))

        if isinstance(start[i], np.datetime64):
            dt = (end[i]-start[i]) / float(n[i]-1)
            dt = _timedelta64_to_higher_unit(dt)
            x[i] = np.arange(start[i], start[i]+dt*(n[i]-1)+np.timedelta64(1,&#39;us&#39;), dt, dtype=start[i].dtype)
        elif random[i]:
            x[i] = np.random.uniform(start[i], end[i], n[i])
        else:
            x[i] = np.linspace(start[i], end[i], n[i])

        N_tile = math.prod(n[:i])
        N_repeat = math.prod(n[i+1:])
        x[i] = np.tile(np.repeat(x[i], N_repeat), N_tile)

    y = f(*x)
    if y.ndim == 2 and y.shape[1] == 1:
        y = y[:,0]
    N = math.prod(n)
    y += np.random.normal(0.0, var, (N,))

    data = Data(x, y, name=name)
    data.set_function(f)
    return data

################################################################
################################################################
################################################################

class Data:
    def __init__(self, X, Y, Y_err=None, name=None, x_labels=None, y_label=None):
        &#34;&#34;&#34;
        Data class that holds all observations, latent functions and predicted data.

        This class accepts the data directly, otherwise you can load data conveniently using `LoadFunction`, `LoadCSV`, `LoadDataFrame`, etc. The data class allows to modify the data before passing into the model. Examples are transforming data, such as detrending or taking the log, removing data ranges to simulate sensor failure, and aggregating data for given spans on X, such as aggregating daily data into weekly data. Additionally, we also use this class to set the range we want to predict.

        It is possible to use the format given by `numpy.meshgrid` for X as a list of numpy arrays for each input dimension, and its values in Y. Each input dimension and Y must have shape (N1,N2,...,Nn) where n is the number of input dimensions and N the number of data points per input dimension.

        Args:
            X (list, numpy.ndarray, dict): Independent variable data of shape (n,) or (n,input_dims), or a list with elements of shape (n,) for each input dimension.
            Y (list, numpy.ndarray): Dependent variable data of shape (n,).
            Y_err (list, numpy.ndarray): Standard deviation of the dependent variable data of shape (n,).
            name (str): Name of data.
            x_labels (str, list of str): Name or names of input dimensions.
            y_label (str): Name of output dimension.

        Examples:
            &gt;&gt;&gt; channel = mogptk.Data([0, 1, 2, 3], [4, 3, 5, 6])
        &#34;&#34;&#34;

        # convert dicts to lists
        if x_labels is not None:
            if isinstance(x_labels, str):
                x_labels = [x_labels]
            if not isinstance(x_labels, list) or not all(isinstance(label, str) for label in x_labels):
                raise ValueError(&#34;x_labels must be a string or list of strings for each input dimension&#34;)

            if isinstance(X, dict):
                it = iter(X.values())
                first = len(next(it))
                if not all(isinstance(x, (list, np.ndarray)) for x in X.values()) or not all(len(x) == first for x in it):
                    raise ValueError(&#34;X dict should contain all lists or np.ndarrays where each has the same length&#34;)
                if not all(key in X for key in x_labels):
                    raise ValueError(&#34;X dict must contain all keys listed in x_labels&#34;)
                X = [X[key] for key in x_labels]

        # check if X is correct
        if isinstance(X, list):
            if all(isinstance(x, list) for x in X):
                m = len(X[0])
                if not all(len(x) == m for x in X[1:]):
                    raise ValueError(&#34;X list items must all be lists of the same length&#34;)
                if not all(all(isinstance(val, (int, float, datetime.datetime, np.datetime64)) for val in x) for x in X):
                    raise ValueError(&#34;X list items must all be lists of numbers or datetime&#34;)
                if not all(_is_homogeneous_type(x) for x in X):
                    raise ValueError(&#34;X list items must all be lists with elements of the same type&#34;)
            elif all(isinstance(x, np.ndarray) for x in X):
                m = len(X[0])
                if not all(len(x) == m for x in X[1:]):
                    raise ValueError(&#34;X list items must all be numpy.ndarrays of the same length&#34;)
            elif not all(isinstance(x, (int, float, datetime.datetime, np.datetime64)) for x in X):
                raise ValueError(&#34;X list items must be all lists, all numpy.ndarrays, or all numbers or datetime&#34;)
            elif not _is_homogeneous_type(X):
                raise ValueError(&#34;X list items must all have elements of the same type&#34;)
            X = [np.array(x) for x in X]
        elif isinstance(X, np.ndarray):
            if X.ndim == 1:
                X = X.reshape(-1, 1)
            if X.ndim != 2:
                raise ValueError(&#34;X must be either a one or two dimensional array of data&#34;)
            X = [X[:,i] for i in range(X.shape[1])]
        else:
            raise ValueError(&#34;X must be list or numpy array, if dict is passed then x_labels must also be set&#34;)

        input_dims = len(X)
        # try to cast unknown data types, X becomes np.float64 or np.datetime64
        for i in range(input_dims):
            if X[i].dtype == np.object_ or np.issubdtype(X[i].dtype, np.character):
                # convert datetime.datetime or strings to np.datetime64
                try:
                    X[i] = X[i].astype(np.datetime64)
                except:
                    raise ValueError(&#34;X data must have a number or datetime data type&#34;)
            elif not np.issubdtype(X[i].dtype, np.datetime64):
                try:
                    X[i] = X[i].astype(np.float64)
                except:
                    raise ValueError(&#34;X data must have a number or datetime data type&#34;)

            # convert X datetime64[us] to a higher unit like s, m, h, D, ...
            if np.issubdtype(X[i].dtype, np.datetime64):
                X[i] = _datetime64_to_higher_unit(X[i])

        # check if Y is correct
        if isinstance(Y, list):
            if not all(isinstance(y, (int, float)) for y in Y):
                raise ValueError(&#34;Y list items must all be numbers&#34;)
            elif not _is_homogeneous_type(Y):
                raise ValueError(&#34;Y list items must all have elements of the same type&#34;)
            Y = np.array(Y)
        elif not isinstance(Y, np.ndarray):
            raise ValueError(&#34;Y must be list or numpy array&#34;)

        # try to cast unknown data types, Y becomes np.float64
        try:
            Y = Y.astype(np.float64)
        except:
            raise ValueError(&#34;Y data must have a number data type&#34;)

        if Y_err is not None:
            # check if Y_err is correct
            if isinstance(Y_err, list):
                if not all(isinstance(y, (int, float)) for y in Y_err):
                    raise ValueError(&#34;Y_err list items must all be numbers&#34;)
                elif not _is_homogeneous_type(Y_err):
                    raise ValueError(&#34;Y_err list items must all have elements of the same type&#34;)
                Y_err = np.array(Y_err)
            elif not isinstance(Y_err, np.ndarray):
                raise ValueError(&#34;Y_err must be list or numpy array&#34;)
            if Y.shape != Y_err.shape:
                raise ValueError(&#34;Y and Y_err must have the same shape&#34;)

            # try to cast unknown data types, Y becomes np.float64
            try:
                Y_err = Y_err.astype(np.float64)
            except:
                raise ValueError(&#34;Y_err data must have a number data type&#34;)

        # convert meshgrids to flat arrays
        if 1 &lt; X[0].ndim and 1 &lt; Y.ndim and X[0].shape == Y.shape:
            X = [np.ravel(x) for x in X]
            Y = np.ravel(Y)
            if Y_err is not None:
                Y_err = np.ravel(Y_err)

        if any(x.ndim != 1 for x in X):
            raise ValueError(&#34;X must be a one dimensional array of data for every input dimension&#34;)
        if Y.ndim != 1:
            raise ValueError(&#34;Y must be a one dimensional array of data&#34;)
        if Y.shape[0] == 0:
            raise ValueError(&#34;X and Y must have a length greater than zero&#34;)
        if any(x.shape[0] != Y.shape[0] for x in X):
            raise ValueError(&#34;X and Y must be of the same length for each input dimension&#34;)


        self.X = [Serie(X[i]) for i in range(input_dims)] # [shape (n)] * input_dims
        self.Y = Serie(Y) # shape (n)
        self.Y_err = None
        if Y_err is not None:
            self.Y_err = Y_err # shape (n)
        self.mask = np.array([True] * Y.shape[0])
        self.F = None
        self.X_pred = None
        self.Y_mu_pred = {}
        self.Y_var_pred = {}
        self.removed_ranges = [[]] * input_dims

        self.X_labels = [&#39;X&#39;] * input_dims
        if 1 &lt; input_dims:
            for i in range(input_dims):
                self.X_labels[i] = &#39;X%d&#39; % (i,)
        if isinstance(x_labels, list) and all(isinstance(item, str) for item in x_labels):
            self.X_labels = x_labels

        self.name = None
        if isinstance(name, str):
            self.name = name
        elif isinstance(y_label, str):
            self.name = y_label

        self.Y_label = &#39;Y&#39;
        if isinstance(y_label, str):
            self.Y_label = y_label

    def __repr__(self):
        df = pd.DataFrame()
        for i in range(len(self.X)):
            df[self.X_labels[i]] = self.X[i]
        df[self.Y_label] = self.Y
        return repr(df)

    def copy(self):
        &#34;&#34;&#34;
        Make a deep copy of `Data`.

        Returns:
            mogptk.data.Data

        Examples:
            &gt;&gt;&gt; other = data.copy()
        &#34;&#34;&#34;
        return copy.deepcopy(self)

    def set_name(self, name):
        &#34;&#34;&#34;
        Set name for data channel.

        Args:
            name (str): Name of data.

        Examples:
            &gt;&gt;&gt; data.set_name(&#39;Channel A&#39;)
        &#34;&#34;&#34;
        self.name = name

    def set_labels(self, x_labels, y_label):
        &#34;&#34;&#34;
        Set axis labels for plots.

        Args:
            x_labels (str, list of str): X data names for each input dimension.
            y_label (str): Y data name for output dimension.

        Examples:
            &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
        &#34;&#34;&#34;
        if isinstance(x_labels, str):
            x_labels = [x_labels]
        elif not isinstance(x_labels, list) or not all(isinstance(item, str) for item in x_labels):
            raise ValueError(&#34;x_labels must be list of strings&#34;)
        if not isinstance(y_label, str):
            raise ValueError(&#34;y_label must be string&#34;)
        if len(x_labels) != self.get_input_dims():
            raise ValueError(&#34;x_labels must have the same input dimensions as the data&#34;)

        self.X_labels = x_labels
        self.Y_label = y_label

    def set_function(self, f):
        &#34;&#34;&#34;
        Set the (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.
    
        The function should take one argument X of shape (n,input_dims) and return Y of shape (n,). If your data has only one input dimension, you can use X[:,0] to select the first (and only) input dimension.

        Args:
            f (function): Function taking X with shape (n,input_dims) and returning shape (n,) as Y.

        Examples:
            &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
        &#34;&#34;&#34;
        _check_function(f, self.get_input_dims(), [x.is_datetime64() for x in self.X])
        self.F = f

    def rescale_x(self, upper=1000.0):
        &#34;&#34;&#34;
        Rescale the X axis so that it is in the interval [0.0,upper]. This helps training most kernels.

        Args:
            upper (float): Upper end of the interval.

        Examples:
            &gt;&gt;&gt; data.rescale_x()
        &#34;&#34;&#34;

        for i in range(self.get_input_dims()):
            X = self.X[i].transformed
            xmin = np.min(X)
            xmax = np.max(X)
            t = TransformLinear(xmin, (xmax-xmin)/upper)
            t.set_data(X)
            self.X[i].apply(t)

    def transform(self, transformer):
        &#34;&#34;&#34;
        Transform the Y axis data by using one of the provided transformers, such as `TransformDetrend`, `TransformLinear`, `TransformLog`, `TransformNormalize`, `TransformStandard`, etc.

        Args:
            transformer (obj): Transformer object derived from TransformBase.

        Examples:
            &gt;&gt;&gt; data.transform(mogptk.TransformDetrend(degree=2))        # remove polynomial trend
            &gt;&gt;&gt; data.transform(mogptk.TransformLinear(slope=1, bias=2))  # remove linear trend
            &gt;&gt;&gt; data.transform(mogptk.TransformLog)                      # log transform the data
            &gt;&gt;&gt; data.transform(mogptk.TransformNormalize)                # transform to [-1,1]
            &gt;&gt;&gt; data.transform(mogptk.TransformStandard)                 # transform to mean=0, var=1
        &#34;&#34;&#34;

        t = transformer
        if isinstance(t, type):
            t = transformer()
        else:
            t = copy.deepcopy(t)
        t.set_data(self)

        self.Y.apply(t, self.X)
    
    def filter(self, start, end, dim=None):
        &#34;&#34;&#34;
        Filter the data range to be between `start` and `end` in the X axis.

        Args:
            start (float, str, list): Start of interval.
            end (float, str, list): End of interval (not included).
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

        Examples:
            &gt;&gt;&gt; data.filter(3, 8)
        
            &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)
        
        if dim is not None:
            ind = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
        else:
            ind = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
            for i in range(1,self.get_input_dims()):
                ind = np.logical_and(ind, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))

        self.X = [x[ind] for x in self.X]
        self.Y = self.Y[ind]
        self.mask = self.mask[ind]

    def aggregate(self, duration, f=np.mean, dim=0):
        &#34;&#34;&#34;
        Aggregate the data by duration and apply a function to obtain a reduced dataset.

        For example, group daily data by week and take the mean. The duration can be set as a number which defined the intervals on the X axis, or by a string written in the duration format in case the X axis has data type `numpy.datetime64`. The duration format uses: Y=year, M=month, W=week, D=day, h=hour, m=minute, and s=second. For example, 3W1D means three weeks and one day, ie. 22 days, or 6M to mean six months.

        Args:
            duration (float, str): Duration along the X axis or as a string in the duration format.
            f (function): Function to use to reduce data mapping a numpy array to a scalar, such as `numpy.mean`.
            dim (int): Input dimension to apply to, defaults to the first input dimension.

        Examples:
            &gt;&gt;&gt; data.aggregate(5)

            &gt;&gt;&gt; data.aggregate(&#39;2W&#39;, f=np.sum)
        &#34;&#34;&#34;
        start = np.min(self.X[dim])
        end = np.max(self.X[dim])
        step = _parse_delta(duration)

        X = np.arange(start+step/2, end+step/2, step)
        Y = np.empty((len(X)))
        for i in range(len(X)):
            ind = (self.X[dim] &gt;= X[i]-step/2) &amp; (self.X[dim] &lt; X[i]+step/2)
            Y[i] = f(self.Y[ind])

        self.X[dim] = Serie(X, self.X[dim].transformers)
        self.Y = Serie(Y, self.Y.transformers, self.X)
        self.mask = np.array([True] * len(self.Y))

    ################################################################

    def get_name(self):
        &#34;&#34;&#34;
        Return the name of the channel.

        Returns:
            str

        Examples:
            &gt;&gt;&gt; data.get_name()
            &#39;A&#39;
        &#34;&#34;&#34;
        return self.name

    def has_test_data(self):
        &#34;&#34;&#34;
        Returns True if observations have been removed using the `remove_*` methods.

        Returns:
            boolean

        Examples:
            &gt;&gt;&gt; data.has_test_data()
            True
        &#34;&#34;&#34;
        return False in self.mask

    def get_input_dims(self):
        &#34;&#34;&#34;
        Returns the number of input dimensions.

        Returns:
            int: Number of input dimensions.

        Examples:
            &gt;&gt;&gt; data.get_input_dims()
            2
        &#34;&#34;&#34;
        return len(self.X)
    
    def get_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns all observations, train and test.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_data()
        &#34;&#34;&#34;
        if transformed:
            return self.X, self.Y.transformed
        return self.X, np.array(self.Y)

    def get_train_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns the observations used for training.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_train_data()
        &#34;&#34;&#34;
        if transformed:
            return [x[self.mask] for x in self.X], self.Y.transformed[self.mask]
        return [x[self.mask] for x in self.X], np.array(self.Y[self.mask])

    def get_test_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns the observations used for testing which correspond to the removed points.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_test_data()
        &#34;&#34;&#34;
        X = [x[~self.mask] for x in self.X]
        if self.F is not None:
            if X[0].shape[0] == 0:
                X, _ = self.get_data()
            Y = self.F(*X)
            if transformed:
                Y = self.Y.transform(Y, X)
            return X, Y
        if transformed:
            return X, self.Y.transformed[~self.mask]
        return X, np.array(self.Y[~self.mask])

    ################################################################

    def reset(self):
        &#34;&#34;&#34;
        Reset the data set and undo the removal of data points. That is, this reverts any calls to `remove_randomly`, `remove_range`, `remove_relative_range`, `remove_random_ranges`, and `remove_index`.
        &#34;&#34;&#34;
        self.mask[:] = True
        for i in range(len(self.removed_ranges)):
            self.removed_ranges[i] = []
    
    def remove_randomly(self, n=None, pct=None):
        &#34;&#34;&#34;
        Removes observations randomly on the whole range. Either `n` observations are removed, or a percentage of the observations.

        Args:
            n (int): Number of observations to remove randomly.
            pct (float): Percentage in interval [0,1] of observations to remove randomly.

        Examples:
            &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

            &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
        &#34;&#34;&#34;
        if n is None:
            if pct is None:
                n = 0
            else:
                n = int(pct * len(self.Y))

        idx = np.random.choice(len(self.Y), n, replace=False)
        self.mask[idx] = False
    
    def remove_range(self, start=None, end=None, dim=None):
        &#34;&#34;&#34;
        Removes observations in the interval `[start,end]`.
        
        Args:
            start (float, str): Start of interval. Defaults to the first value in observations.
            end (float, str): End of interval (not included). Defaults to the last value in observations.
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

        Examples:
            &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.remove_range(3, 8)
        
            &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
            &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if start is None:
            start = [np.min(x) for x in self.X]
        if end is None:
            end = [np.max(x) for x in self.X]

        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)

        if dim is not None:
            mask = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
            self.removed_ranges[dim].append([start[dim], end[dim]])
        else:
            mask = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
            for i in range(1,self.get_input_dims()):
                mask = np.logical_or(mask, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))
            for i in range(self.get_input_dims()):
                self.removed_ranges[i].append([start[i], end[i]])
        self.mask[np.where(mask)] = False
    
    def remove_relative_range(self, start=0.0, end=1.0, dim=None):
        &#34;&#34;&#34;
        Removes observations between `start` and `end` as a percentage of the number of observations. So `0` is the first observation, `0.5` is the middle observation, and `1` is the last observation.

        Args:
            start (float): Start percentage in interval [0,1].
            end (float): End percentage in interval [0,1].
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.
        &#34;&#34;&#34;
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)

        x_min = [np.min(x) for x in self.X]
        x_max = [np.max(x) for x in self.X]
        for i in range(self.get_input_dims()):
            start[i] = x_min[i] + max(0.0, min(1.0, start[i])) * (x_max[i]-x_min[i])
            end[i] = x_min[i] + max(0.0, min(1.0, end[i])) * (x_max[i]-x_min[i])

        self.remove_range(start, end, dim)

    def remove_random_ranges(self, n, duration, dim=0):
        &#34;&#34;&#34;
        Removes a number of ranges to simulate sensor failure. May remove fewer ranges if there is no more room to remove a range in the remaining data.

        Args:
            n (int): Number of ranges to remove.
            duration (float, str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).
            dim (int): Input dimension to apply to, defaults to the first input dimension.

        Examples:
            &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

            &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
        &#34;&#34;&#34;
        if n &lt; 1:
            return

        delta = _parse_delta(duration)
        m = (np.max(self.X[dim])-np.min(self.X[dim])) - n*delta
        if m &lt;= 0:
            raise ValueError(&#34;no data left after removing ranges&#34;)

        locs = self.X[dim] &lt;= (np.max(self.X[dim])-delta)
        locs[sum(locs)] = True # make sure the last data point can be deleted
        for i in range(n):
            if len(self.X[dim][locs]) == 0:
                break # range could not be removed, there is no remaining data range of width delta
            x = self.X[dim][locs][np.random.randint(len(self.X[dim][locs]))]
            locs[(self.X[dim] &gt; x-delta) &amp; (self.X[dim] &lt; x+delta)] = False
            self.mask[(self.X[dim] &gt;= x) &amp; (self.X[dim] &lt; x+delta)] = False
            self.removed_ranges[dim].append([x, x+delta])

    def remove_index(self, index):
        &#34;&#34;&#34;
        Removes observations of given index

        Args:
            index(list, numpy.ndarray): Array of indexes of the data to remove.
        &#34;&#34;&#34;
        if isinstance(index, list):
            index = np.array(index)
        elif not isinstance(index, np.ndarray):
            raise ValueError(&#34;index must be list or numpy array&#34;)

        self.mask[index] = False
    
    ################################################################
    
    def get_prediction_names(self):
        &#34;&#34;&#34;
        Returns the model names of the saved predictions.

        Returns:
            list: List of prediction names.

        Examples:
            &gt;&gt;&gt; data.get_prediction_names()
            [&#39;MOSM&#39;, &#39;CSM&#39;, &#39;SM-LMC&#39;, &#39;CONV&#39;]
        &#34;&#34;&#34;
        return self.Y_mu_pred.keys()
    
    def get_prediction_x(self):
        &#34;&#34;&#34;
        Returns the prediction X range.

        Returns:
            numpy.ndarray: X prediction of shape [(n,)] * input_dims.

        Examples:
            &gt;&gt;&gt; x = data.get_prediction_x()
        &#34;&#34;&#34;
        if self.X_pred is None:
            return self.X.copy()
        return self.X_pred.copy()
    
    def get_prediction(self, name, sigma=2.0, transformed=False):
        &#34;&#34;&#34;
        Returns the prediction of a given name with a confidence interval of `sigma` times the standard deviation.

        Args:
            name (str): Name of the model of the prediction.
            sigma (float): The confidence interval&#39;s number of standard deviations.
            transformed (boolean): Return transformed data as used for training.

        Returns:
            numpy.ndarray: X prediction of shape [(n,)] * input_dims.
            numpy.ndarray: Y mean prediction of shape (n,).
            numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
            numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y_mean, y_var_lower, y_var_upper = data.get_prediction(&#39;MOSM&#39;, sigma=1)
        &#34;&#34;&#34;
        if name not in self.Y_mu_pred:
            raise ValueError(&#34;prediction name &#39;%s&#39; does not exist&#34; % (name))
       
        if self.X_pred is None:
            X = self.X.copy()
        else:
            X = self.X_pred.copy()
        mu = self.Y_mu_pred[name]
        lower = mu - sigma*np.sqrt(self.Y_var_pred[name])
        upper = mu + sigma*np.sqrt(self.Y_var_pred[name])

        if transformed:
            return X, mu, lower, upper

        mu = Serie(self.Y.detransform(mu, X), self.Y.transformers, transformed=mu)
        lower = Serie(self.Y.detransform(lower, X), self.Y.transformers, transformed=lower)
        upper = Serie(self.Y.detransform(upper, X), self.Y.transformers, transformed=upper)
        return X, mu, lower, upper

    def _format_prediction_x(self, X):
        if isinstance(X, np.ndarray):
            if X.ndim == 1:
                X = X.reshape(-1,1)
            if X.ndim != 2 or X.shape[1] != self.get_input_dims():
                raise ValueError(&#34;X shape must be (n,input_dims) for each channel&#34;)
            X = [X[:,i] for i in range(self.get_input_dims())]
        elif not isinstance(X, list):
            raise ValueError(&#34;X expected to be a list or numpy.ndarray for each channel&#34;)
        if not all(x.ndim == 1 for x in X) or len(X) != self.get_input_dims():
            raise ValueError(&#34;X shape must be (n,), (n,input_dims), or [(n,)] * input_dims for each channel&#34;)
        X = [X[i].astype(self.X[i].dtype) for i in range(self.get_input_dims())]
        return X

    def set_prediction_x(self, X):
        &#34;&#34;&#34;
        Set the prediction range directly for saved predictions. This will clear old predictions.

        Args:
            X (list, numpy.ndarray): Array of shape (n,), (n,input_dims), or [(n,)] * input_dims used for predictions.

        Examples:
            &gt;&gt;&gt; data.set_prediction_x([5.0, 5.5, 6.0, 6.5, 7.0])
        &#34;&#34;&#34;
        X = self._format_prediction_x(X)
        self.X_pred = [Serie(X[i], self.X[i].transformers) for i in range(self.get_input_dims())]

        # clear old prediction data now that X_pred has been updated
        self.clear_predictions()

    def set_prediction_range(self, start=None, end=None, n=None, step=None):
        &#34;&#34;&#34;
        Sets the prediction range. The interval is set as `[start,end]`, with either `n` points or a given step between the points.

        Args:
            start (float, str, list): Start of interval, defaults to the first observation.
            end (float, str, list): End of interval, defaults to the last observation.
            n (int, list): Number of points to generate in the interval.
            step (float, str, list): Spacing between points in the interval.

            If neither step or n is passed, default number of points is 100.

        Examples:
            &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.set_prediction_range(3, 8, 200)
        
            &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
            &gt;&gt;&gt; data.set_prediction_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1D&#39;)
        &#34;&#34;&#34;
        if start is None:
            start = [x[0] for x in self.X]
        if end is None:
            end = [x[-1] for x in self.X]
        
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)
        n = self._normalize_val(n)
        step = self._normalize_val(step)
        for i in range(self.get_input_dims()):
            if n is not None and not isinstance(n[i], int):
                raise ValueError(&#34;n must be integer&#34;)
            if step is not None and np.issubdtype(self.X[i].dtype, np.datetime64):
                step[i] = _parse_delta(step[i])

        if np.any(end &lt;= start):
            raise ValueError(&#34;start must be lower than end&#34;)

        # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
        X_pred = [np.array([])] * self.get_input_dims()
        for i in range(self.get_input_dims()):
            if n is not None and n[i] is not None:
                X_pred[i] = start[i] + (end[i]-start[i])*np.linspace(0.0, 1.0, int(n[i]))
            else:
                if step is None or step[i] is None:
                    x_step = (end[i]-start[i])/100
                else:
                    x_step = _parse_delta(step[i])
                X_pred[i] = np.arange(start[i], end[i]+x_step, x_step)
        self.X_pred = [Serie(x, self.X[i].transformers) for i, x in enumerate(X_pred)]

        # clear old prediction data now that X_pred has been updated
        self.clear_predictions()

    def clear_predictions(self):
        &#34;&#34;&#34;
        Clear all saved predictions.
        &#34;&#34;&#34;
        self.Y_mu_pred = {}
        self.Y_var_pred = {}

    ################################################################

    def get_nyquist_estimation(self):
        &#34;&#34;&#34;
        Estimate the Nyquist frequency by taking 0.5/(minimum distance of points).

        Returns:
            numpy.ndarray: Nyquist frequency array of shape (input_dims,).

        Examples:
            &gt;&gt;&gt; freqs = data.get_nyquist_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        nyquist = np.empty((input_dims,))
        for i in range(self.get_input_dims()):
            x = np.sort(self.X[i].transformed[self.mask])
            dist = np.abs(x[1:]-x[:-1])
            dist = np.min(dist[np.nonzero(dist)])
            nyquist[i] = 0.5/dist
        return nyquist

    def _get_psd_peaks(self, w, psd):
        peaks, _ = signal.find_peaks(psd)
        if len(peaks) == 0:
            return np.array([]), np.array([]), np.array([])
        peaks = peaks[np.argsort(psd[peaks])[::-1]] # sort by biggest peak first

        widths, width_heights, _, _ = signal.peak_widths(psd, peaks, rel_height=0.5)
        widths *= w[1]-w[0]

        positions = w[peaks]
        amplitudes = psd[peaks]
        variances = widths / np.sqrt(8 * np.log(amplitudes / width_heights)) # from full-width half-maximum to Gaussian sigma
        return amplitudes, positions, variances

    def get_lombscargle_estimation(self, Q=1, n=10000):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using Lomb-Scargle.

        Args:
            Q (int): Number of peaks to find.
            n (int): Number of points to use for Lomb-Scargle.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_lombscargle_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # i.e. A is the amplitude or peak height, B the mean or peak position, and C the std.dev. or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
            w = np.linspace(0.0, nyquist[i], n+1)[1:]
            psd = signal.lombscargle(x[:,i]*2.0*np.pi, y, w)

            amplitudes, positions, variances = self._get_psd_peaks(w, psd)
            if len(positions) == 0:
                continue
            if Q &lt; len(amplitudes):
                amplitudes = amplitudes[:Q]
                positions = positions[:Q]
                variances = variances[:Q]

            n = len(amplitudes)
            A[:n,i] = np.sqrt(amplitudes)
            B[:n,i] = positions
            C[:n,i] = variances
        return A, B, C

    def get_bnse_estimation(self, Q=1, n=1000):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using BNSE (Bayesian Non-parametric Spectral Estimation).

        Args:
            Q (int): Number of peaks to find.
            n (int): Number of points of the grid to evaluate frequencies.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_bnse_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
            w, psd = BNSE(x[:,i], y, max_freq=nyquist[i], n=n)
            amplitudes, positions, variances = self._get_psd_peaks(w[:,0], psd[:,0])
            if len(positions) == 0:
                continue

            if Q &lt; len(amplitudes):
                amplitudes = amplitudes[:Q]
                positions = positions[:Q]
                variances = variances[:Q]

            num = len(amplitudes)
            # division by 100 makes it similar to other estimators (emperically found) TODO: remove?
            A[:num,i] = np.sqrt(amplitudes) / 100
            B[:num,i] = positions
            C[:num,i] = variances
        return A, B, C

    def get_sm_estimation(self, Q=1, method=&#39;LS&#39;, optimizer=&#39;Adam&#39;, iters=100, params={}, plot=False):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using the spectral mixture kernel.

        Args:
            Q (int): Number of peaks to find.
            method (str): Method of estimating SM kernels.
            optimizer (str): Optimization method for SM kernels.
            iters (str): Maximum iteration for SM kernels.
            params (object): Additional parameters for the PyTorch optimizer.
            plot (bool): Show the PSD of the kernel after fitting.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_sm_estimation()
        &#34;&#34;&#34;
        from .models.sm import SM

        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        sm = SM(self, Q)
        sm.init_parameters(method)
        sm.train(method=optimizer, iters=iters, **params)

        if plot:
            nyquist = self.get_nyquist_estimation()
            means = np.array([sm.gpr.kernel[0][q].mean.numpy() for q in range(Q)])
            weights = np.array([sm.gpr.kernel[0][q].sigma.numpy()**2 for q in range(Q)])
            scales = np.array([sm.gpr.kernel[0][q].variance.numpy() for q in range(Q)])
            nyquist = np.expand_dims(nyquist, 0)
            means = np.expand_dims(means, 1)
            scales = np.expand_dims(scales, 1)
            plot_spectrum(means, scales, weights=weights, nyquist=nyquist, title=self.name)

        for q in range(Q):
            A[q,:] = sm.gpr.kernel[0][q].sigma.numpy()**2  # TODO: weight is not per input_dims
            B[q,:] = sm.gpr.kernel[0][q].mean.numpy()
            C[q,:] = sm.gpr.kernel[0][q].variance.numpy()
        return A, B, C

    def plot(self, pred=None, title=None, ax=None, legend=True, errorbars=True, transformed=False):
        &#34;&#34;&#34;
        Plot the data including removed observations, latent function, and predictions.

        Args:
            pred (str): Specify model name to draw.
            title (str): Set the title of the plot.
            ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
            legend (boolean): Display legend.
            transformed (boolean): Display transformed Y data as used for training.

        Returns:
            matplotlib.axes.Axes

        Examples:
            &gt;&gt;&gt; ax = data.plot()
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)

        legends = []
        if errorbars and self.Y_err is not None:
            x, y = self.get_train_data(transformed=transformed)
            yl = self.Y[self.mask] - self.Y_err[self.mask]
            yu = self.Y[self.mask] + self.Y_err[self.mask]
            if transformed:
                yl = self.Y.transform(yl, x)
                yu = self.Y.transform(yu, x)
            plt.errorbar(x[0], y, [y-yl, yu-y], elinewidth=0.5, ecolor=&#39;k&#39;, capsize=0, ls=&#39;&#39;, marker=&#39;&#39;)

        colors = list(matplotlib.colors.TABLEAU_COLORS)
        for i, name in enumerate(self.Y_mu_pred):
            if self.Y_mu_pred[name].size != 0 and (pred is None or name.lower() == pred.lower()):
                X_pred, mu, lower, upper = self.get_prediction(name, transformed=transformed)

                idx = np.argsort(X_pred[0])
                ax.plot(X_pred[0][idx], mu[idx], ls=&#39;-&#39;, color=colors[i], lw=2)
                ax.fill_between(X_pred[0][idx], lower[idx], upper[idx], color=colors[i], alpha=0.1)
                #ax.plot(X_pred[:,0][idx], lower[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)
                #ax.plot(X_pred[:,0][idx], upper[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)

                label = &#39;Prediction&#39;
                if name is not None:
                    label += &#39; &#39; + name
                legends.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=colors[i], lw=2, label=label))

        if self.F is not None:
            if self.X_pred is None:
                xmin = np.min(self.X[0])
                xmax = np.max(self.X[0])
            else:
                xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
                xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))

            if np.issubdtype(self.X[0].dtype, np.datetime64):
                dt = np.timedelta64(1,self.X[0].get_time_unit())
                n = int((xmax-xmin) / dt) + 1
                x = np.arange(xmin, xmax+np.timedelta64(1,&#39;us&#39;), dt, dtype=self.X[0].dtype)
            else:
                n = len(self.X[0])*10
                x = np.linspace(xmin, xmax, n)

            x = [x]
            y = self.F(*x)
            if transformed:
                y = self.Y.transform(y, x)

            ax.plot(x[0], y, &#39;r--&#39;, lw=1)
            legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;True&#39;))

        _, Y = self.get_data(transformed=transformed)
        idx = np.argsort(self.X[0])
        ax.plot(self.X[0][idx], Y[idx], &#39;k--&#39;, alpha=0.8)
        legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;k&#39;, label=&#39;All Points&#39;))

        x, y = self.get_train_data(transformed=transformed)
        ax.plot(x[0], y, &#39;k.&#39;, mew=0.5, ms=10, markeredgecolor=&#39;white&#39;)
        legends.append(plt.Line2D([0], [0], ls=&#39;&#39;, color=&#39;k&#39;, marker=&#39;.&#39;, ms=10, label=&#39;Training Points&#39;))

        if self.has_test_data():
            for removed_range in self.removed_ranges[0]:
                x0 = removed_range[0]
                x1 = removed_range[1]
                y0 = ax.get_ylim()[0]
                y1 = ax.get_ylim()[1]
                ax.add_patch(patches.Rectangle(
                    (x0, y0), x1-x0, y1-y0, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.2, lw=0,
                ))
            legends.append(patches.Rectangle(
                (1, 1), 1, 1, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.5, lw=0, label=&#39;Removed Ranges&#39;
            ))

        if self.X_pred is None:
            xmin = np.min(self.X[0])
            xmax = np.max(self.X[0])
        else:
            xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
            xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))
        ax.set_xlim(xmin - (xmax - xmin)*0.001, xmax + (xmax - xmin)*0.001)

        ax.set_xlabel(self.X_labels[0])
        ax.set_ylabel(self.Y_label)
        ax.set_title(self.name if title is None else title, fontsize=14)

        if legend:
            legend_rows = (len(legends)-1)/5 + 1
            ax.legend(handles=legends, loc=&#34;upper center&#34;, bbox_to_anchor=(0.5,(3.0+0.5+0.3*legend_rows)/3.0), ncol=5)

        return ax

    def plot_spectrum(self, title=None, method=&#39;ls&#39;, ax=None, per=None, maxfreq=None, log=False, transformed=True, n=1001):
        &#34;&#34;&#34;
        Plot the spectrum of the data.

        Args:
            title (str): Set the title of the plot.
            method (str): Set the method to get the spectrum such as LS or BNSE.
            ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
            per (str, float, numpy.timedelta64): Set the scale of the X axis depending on the formatter used, eg. per=5, per=&#39;day&#39;, or per=&#39;3D&#39;.
            maxfreq (float): Maximum frequency to plot, otherwise the Nyquist frequency is used.
            log (boolean): Show X and Y axis in log-scale.
            transformed (boolean): Display transformed Y data as used for training.
            n (int): Number of points used for periodogram.

        Returns:
            matplotlib.axes.Axes

        Examples:
            &gt;&gt;&gt; ax = data.plot_spectrum(method=&#39;bnse&#39;)
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

        ax_set = ax is not None
        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)
        
        X_scale = 1.0
        if np.issubdtype(self.X[0].dtype, np.datetime64):
            if per is None:
                per = _datetime64_unit_names[self.X[0].get_time_unit()]
            else:
                unit = _parse_delta(per)
                X_scale = np.timedelta64(1,self.X[0].get_time_unit()) / unit
                if not isinstance(per, str):
                    per = &#39;%s&#39; % (unit,)

        if per is not None:
            ax.set_xlabel(&#39;Frequency [1/&#39;+per+&#39;]&#39;)
        else:
            ax.set_xlabel(&#39;Frequency&#39;)
        
        X = self.X[0].astype(np.float)
        Y = self.Y
        if transformed:
            Y = self.Y.transformed

        idx = np.argsort(X)
        X = X[idx] * X_scale
        Y = Y[idx]

        nyquist = maxfreq
        if nyquist is None:
            dist = np.abs(X[1:]-X[:-1])
            nyquist = float(0.5 / np.average(dist))

        if method.lower() == &#39;ls&#39;:
            X_freq = np.linspace(0.0, nyquist, n)[1:]
            Y_freq = signal.lombscargle(X*2.0*np.pi, Y, X_freq, normalize=True)
        elif method.lower() == &#39;bnse&#39;:
            X_freq, Y_freq = BNSE(np.array(X), np.array(Y), max_freq=nyquist, n=n)
        else:
            raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

        # TODO: normalize periodograms
        # normalize
        #Y_freq /= Y_freq.sum() * (X_freq[1]-X_freq[0])

        ax.plot(X_freq, Y_freq, &#39;-&#39;, c=&#39;k&#39;, lw=2)
        #if len(Y_freq_err) != 0:
        #    ax.fill_between(X_freq, Y_freq-Y_freq_err, Y_freq+Y_freq_err, alpha=0.4)
        ax.set_title((self.name + &#39; Spectrum&#39; if self.name is not None else &#39;&#39;) if title is None else title, fontsize=14)

        if log:
            ax.set_xscale(&#39;log&#39;)
            ax.set_yscale(&#39;log&#39;)

        if not ax_set:
            xmin = X_freq.min()
            xmax = X_freq.max()
            ax.set_xlim(xmin - (xmax - xmin)*0.005, xmax + (xmax - xmin)*0.005)
            ax.set_yticks([])
            ax.set_ylim(0, None)
        return ax

    def _normalize_val(self, val):
        # normalize input values, that is: expand to input_dims if a single value
        if val is None:
            return val
        if isinstance(val, np.ndarray):
            if val.ndim == 0:
                val = [val.item()]
            else:
                val = list(val)
        elif _is_iterable(val):
            val = list(val)
        else:
            val = [val] * self.get_input_dims()
        if len(val) != self.get_input_dims():
            raise ValueError(&#34;value must be a scalar or a list of values for each input dimension&#34;)
        return val

    def _normalize_x_val(self, val):
        # normalize input values for X axis, that is: expand to input_dims if a single value, convert values to appropriate dtype
        val = self._normalize_val(val)
        for i in range(self.get_input_dims()):
            try:
                val[i] = self.X[i].dtype.type(val[i])
            except:
                raise ValueError(&#34;value must be of type %s&#34; % (self.X[i].dtype,))
        return val

def _is_iterable(val):
    return isinstance(val, collections.abc.Iterable) and not isinstance(val, (dict, str))

def _is_homogeneous_type(seq):
    it = iter(seq)
    first = type(next(it))
    return all(type(x) is first for x in it)

def _check_function(f, input_dims, is_datetime64):
    if not inspect.isfunction(f):
        raise ValueError(&#34;must pass a function with input dimensions as parameters&#34;)

    sig = inspect.signature(f)
    if len(sig.parameters) != input_dims:
        raise ValueError(&#34;must pass a function with input dimensions as parameters&#34;)

    x = [np.array([np.datetime64(&#39;2000&#39;, &#39;us&#39;)]) if is_datetime64[i] else np.ones((1,)) for i in range(input_dims)]
    y = f(*x)
    if y.ndim != 1 or y.shape[0] != 1:
        raise ValueError(&#34;function must return Y with shape (n,), note that all inputs are of shape (n,)&#34;)

_datetime64_unit_names = {
    &#39;Y&#39;: &#39;year&#39;,
    &#39;M&#39;: &#39;month&#39;,
    &#39;W&#39;: &#39;week&#39;,
    &#39;D&#39;: &#39;day&#39;,
    &#39;h&#39;: &#39;hour&#39;,
    &#39;m&#39;: &#39;minute&#39;,
    &#39;s&#39;: &#39;second&#39;,
    &#39;ms&#39;: &#39;millisecond&#39;,
    &#39;us&#39;: &#39;microsecond&#39;,
}
    
duration_regex = re.compile(
    r&#39;^((?P&lt;years&gt;[\.\d]+?)y)?&#39;
    r&#39;((?P&lt;months&gt;[\.\d]+?)M)?&#39;
    r&#39;((?P&lt;weeks&gt;[\.\d]+?)W)?&#39;
    r&#39;((?P&lt;days&gt;[\.\d]+?)D)?&#39;
    r&#39;((?P&lt;hours&gt;[\.\d]+?)h)?&#39;
    r&#39;((?P&lt;minutes&gt;[\.\d]+?)m)?&#39;
    r&#39;((?P&lt;seconds&gt;[\.\d]+?)s)?$&#39;
    r&#39;((?P&lt;milliseconds&gt;[\.\d]+?)ms)?$&#39;
    r&#39;((?P&lt;microseconds&gt;[\.\d]+?)us)?$&#39;
)

def _parse_delta(text):
    if not isinstance(text, str):
        return text

    if text == &#39;year&#39; or text == &#39;years&#39;:
        return np.timedelta64(1, &#39;Y&#39;)
    elif text == &#39;month&#39; or text == &#39;months&#39;:
        return np.timedelta64(1, &#39;M&#39;)
    elif text == &#39;week&#39; or text == &#39;weeks&#39;:
        return np.timedelta64(1, &#39;W&#39;)
    elif text == &#39;day&#39; or text == &#39;days&#39;:
        return np.timedelta64(1, &#39;D&#39;)
    elif text == &#39;hour&#39; or text == &#39;hours&#39;:
        return np.timedelta64(1, &#39;h&#39;)
    elif text == &#39;minute&#39; or text == &#39;minutes&#39;:
        return np.timedelta64(1, &#39;m&#39;)
    elif text == &#39;second&#39; or text == &#39;seconds&#39;:
        return np.timedelta64(1, &#39;s&#39;)
    elif text == &#39;millisecond&#39; or text == &#39;milliseconds&#39;:
        return np.timedelta64(1, &#39;ms&#39;)
    elif text == &#39;microsecond&#39; or text == &#39;microseconds&#39;:
        return np.timedelta64(1, &#39;us&#39;)

    m = duration_regex.match(text)
    if m is None:
        raise ValueError(&#39;duration string must be of the form 2h45m, allowed characters: (Y)ear, (M)onth, (W)eek, (D)ay, (h)our, (m)inute, (s)econd, (ms) for milliseconds, (us) for microseconds&#39;)

    delta = 0
    matches = m.groupdict()
    if matches[&#39;years&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;years&#39;]), &#39;Y&#39;)
    if matches[&#39;months&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;months&#39;]), &#39;M&#39;)
    if matches[&#39;weeks&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;weeks&#39;]), &#39;W&#39;)
    if matches[&#39;days&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;days&#39;]), &#39;D&#39;)
    if matches[&#39;hours&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;hours&#39;]), &#39;h&#39;)
    if matches[&#39;minutes&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;minutes&#39;]), &#39;m&#39;)
    if matches[&#39;seconds&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;seconds&#39;]), &#39;s&#39;)
    if matches[&#39;milliseconds&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;milliseconds&#39;]), &#39;ms&#39;)
    if matches[&#39;microseconds&#39;]:
        delta += np.timedelta64(np.int32(matches[&#39;microseconds&#39;]), &#39;us&#39;)
    return delta

def _datetime64_to_higher_unit(array):
    if array.dtype in [&#39;&lt;M8[Y]&#39;, &#39;&lt;M8[M]&#39;, &#39;&lt;M8[W]&#39;, &#39;&lt;M8[D]&#39;]:
        return array

    units = [&#39;D&#39;, &#39;h&#39;, &#39;m&#39;, &#39;s&#39;]  # cannot convert days to non-linear months or years
    for unit in units:
        frac, _ = np.modf((array-np.datetime64(&#39;2000&#39;)) / np.timedelta64(1,unit))
        if not np.any(frac):
            return array.astype(&#39;datetime64[%s]&#39; % (unit,))
    return array

def _timedelta64_to_higher_unit(array):
    if array.dtype in [&#39;&lt;m8[Y]&#39;, &#39;&lt;m8[M]&#39;, &#39;&lt;m8[W]&#39;, &#39;&lt;m8[D]&#39;]:
        return array

    units = [&#39;D&#39;, &#39;h&#39;, &#39;m&#39;, &#39;s&#39;]  # cannot convert days to non-linear months or years
    for unit in units:
        frac, _ = np.modf(array / np.timedelta64(1,unit))
        if not np.any(frac):
            return array.astype(&#39;timedelta64[%s]&#39; % (unit,))
    return array</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mogptk.data.LoadFunction"><code class="name flex">
<span>def <span class="ident">LoadFunction</span></span>(<span>f, start, end, n, var=0.0, name='', random=False)</span>
</code></dt>
<dd>
<div class="desc"><p>LoadFunction loads a dataset from a given function y = f(x) + Normal(0,var). It will pick <code>n</code> data points between start and end for the X axis for which <code>f</code> is being evaluated. By default the <code>n</code> points are spread equally over the interval, with <code>random=True</code> they will be picked randomly.</p>
<p>The given function should take one argument X which is a list of <code>numpy.ndarray</code> of shape (n,) for every input dimension and returns an <code>numpy.ndarray</code> Y of shape (n,). If your data has only one input dimension, you can use X[0] to select the first (and only) input dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code></dt>
<dd>Function taking X a list with elements of shape (n,) for each input dimension and returning shape (n,) as Y.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>float, list</code></dt>
<dd>Define start of interval.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float, list</code></dt>
<dd>Define end of interval.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int, list</code></dt>
<dd>Number of data points to pick between start and end.</dd>
<dt><strong><code>var</code></strong> :&ensp;<code>float</code></dt>
<dd>Variance added to the output.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of data.</dd>
<dt><strong><code>random</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Select points randomly between start and end.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>mogptk.data.Data</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&lt;mogptk.data.Data at ...&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L25-L140" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def LoadFunction(f, start, end, n, var=0.0, name=&#34;&#34;, random=False):
    &#34;&#34;&#34;
    LoadFunction loads a dataset from a given function y = f(x) + Normal(0,var). It will pick `n` data points between start and end for the X axis for which `f` is being evaluated. By default the `n` points are spread equally over the interval, with `random=True` they will be picked randomly.

    The given function should take one argument X which is a list of `numpy.ndarray` of shape (n,) for every input dimension and returns an `numpy.ndarray` Y of shape (n,). If your data has only one input dimension, you can use X[0] to select the first (and only) input dimension.

    Args:
        f (function): Function taking X a list with elements of shape (n,) for each input dimension and returning shape (n,) as Y.
        start (float, list): Define start of interval.
        end (float, list): Define end of interval.
        n (int, list): Number of data points to pick between start and end.
        var (float): Variance added to the output.
        name (str): Name of data.
        random (boolean): Select points randomly between start and end.

    Returns:
        mogptk.data.Data

    Examples:
        &gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;

    if isinstance(start, np.ndarray):
        if start.ndim == 0:
            start = [start.item()]
        else:
            start = list(start)
    elif _is_iterable(start):
        start = list(start)
    else:
        start = [start]
    if isinstance(end, np.ndarray):
        if end.ndim == 0:
            end = [end.item()]
        else:
            end = list(end)
    elif _is_iterable(end):
        end = list(end)
    else:
        end = [end]
    if type(start[0]) is not type(end[0]):
        raise ValueError(&#34;start and end must be of the same type&#34;)
    if len(start) != len(end):
        raise ValueError(&#34;start and end must be of the same length&#34;)

    input_dims = len(start)
    for i in range(input_dims):
        if not _is_homogeneous_type([start[i] + end[i]]):
            raise ValueError(&#34;start and end must have elements of the same type&#34;)

        if isinstance(start[i], datetime.datetime) or isinstance(start[i], str) or isinstance(start[i], np.datetime64):
            try:
                start[i] = np.datetime64(start[i], &#39;us&#39;)
                end[i] = np.datetime64(end[i], &#39;us&#39;)
            except:
                raise ValueError(&#34;start and end must have matching number or datetime data type&#34;)
        else:
            try:
                start[i] = np.float64(start[i])
                end[i] = np.float64(end[i])
            except:
                raise ValueError(&#34;start and end must have matching number or datetime data type&#34;)

    _check_function(f, input_dims, [isinstance(start[i], np.datetime64) for i in range(input_dims)])

    if _is_iterable(n):
        n = list(n)
    else:
        n = [n] * input_dims
    if len(n) != input_dims:
        raise ValueError(&#34;n must be a scalar or a list of values for each input dimension&#34;)
    if _is_iterable(random):
        random = list(random)
    else:
        random = [random] * input_dims
    if len(random) != input_dims:
        raise ValueError(&#34;random must be a scalar or a list of values for each input dimension&#34;)

    for i in range(input_dims):
        if random[i] and isinstance(start[i], np.datetime64):
            if input_dims == 1:
                raise ValueError(&#34;cannot use random for datetime inputs for input dimension %d&#34;, (i,))
            else:
                raise ValueError(&#34;cannot use random for datetime inputs&#34;)

    x = [None] * input_dims
    for i in range(input_dims):
        if start[i] &gt;= end[i]:
            if input_dims == 1:
                raise ValueError(&#34;start must be lower than end&#34;)
            else:
                raise ValueError(&#34;start must be lower than end for input dimension %d&#34; % (i,))

        if isinstance(start[i], np.datetime64):
            dt = (end[i]-start[i]) / float(n[i]-1)
            dt = _timedelta64_to_higher_unit(dt)
            x[i] = np.arange(start[i], start[i]+dt*(n[i]-1)+np.timedelta64(1,&#39;us&#39;), dt, dtype=start[i].dtype)
        elif random[i]:
            x[i] = np.random.uniform(start[i], end[i], n[i])
        else:
            x[i] = np.linspace(start[i], end[i], n[i])

        N_tile = math.prod(n[:i])
        N_repeat = math.prod(n[i+1:])
        x[i] = np.tile(np.repeat(x[i], N_repeat), N_tile)

    y = f(*x)
    if y.ndim == 2 and y.shape[1] == 1:
        y = y[:,0]
    N = math.prod(n)
    y += np.random.normal(0.0, var, (N,))

    data = Data(x, y, name=name)
    data.set_function(f)
    return data</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mogptk.data.Data"><code class="flex name class">
<span>class <span class="ident">Data</span></span>
<span>(</span><span>X, Y, Y_err=None, name=None, x_labels=None, y_label=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Data class that holds all observations, latent functions and predicted data.</p>
<p>This class accepts the data directly, otherwise you can load data conveniently using <code><a title="mogptk.data.LoadFunction" href="#mogptk.data.LoadFunction">LoadFunction()</a></code>, <code>LoadCSV</code>, <code>LoadDataFrame</code>, etc. The data class allows to modify the data before passing into the model. Examples are transforming data, such as detrending or taking the log, removing data ranges to simulate sensor failure, and aggregating data for given spans on X, such as aggregating daily data into weekly data. Additionally, we also use this class to set the range we want to predict.</p>
<p>It is possible to use the format given by <code>numpy.meshgrid</code> for X as a list of numpy arrays for each input dimension, and its values in Y. Each input dimension and Y must have shape (N1,N2,&hellip;,Nn) where n is the number of input dimensions and N the number of data points per input dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list, numpy.ndarray, dict</code></dt>
<dd>Independent variable data of shape (n,) or (n,input_dims), or a list with elements of shape (n,) for each input dimension.</dd>
<dt><strong><code>Y</code></strong> :&ensp;<code>list, numpy.ndarray</code></dt>
<dd>Dependent variable data of shape (n,).</dd>
<dt><strong><code>Y_err</code></strong> :&ensp;<code>list, numpy.ndarray</code></dt>
<dd>Standard deviation of the dependent variable data of shape (n,).</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of data.</dd>
<dt><strong><code>x_labels</code></strong> :&ensp;<code>str, list</code> of <code>str</code></dt>
<dd>Name or names of input dimensions.</dd>
<dt><strong><code>y_label</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of output dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; channel = mogptk.Data([0, 1, 2, 3], [4, 3, 5, 6])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L146-L1276" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Data:
    def __init__(self, X, Y, Y_err=None, name=None, x_labels=None, y_label=None):
        &#34;&#34;&#34;
        Data class that holds all observations, latent functions and predicted data.

        This class accepts the data directly, otherwise you can load data conveniently using `LoadFunction`, `LoadCSV`, `LoadDataFrame`, etc. The data class allows to modify the data before passing into the model. Examples are transforming data, such as detrending or taking the log, removing data ranges to simulate sensor failure, and aggregating data for given spans on X, such as aggregating daily data into weekly data. Additionally, we also use this class to set the range we want to predict.

        It is possible to use the format given by `numpy.meshgrid` for X as a list of numpy arrays for each input dimension, and its values in Y. Each input dimension and Y must have shape (N1,N2,...,Nn) where n is the number of input dimensions and N the number of data points per input dimension.

        Args:
            X (list, numpy.ndarray, dict): Independent variable data of shape (n,) or (n,input_dims), or a list with elements of shape (n,) for each input dimension.
            Y (list, numpy.ndarray): Dependent variable data of shape (n,).
            Y_err (list, numpy.ndarray): Standard deviation of the dependent variable data of shape (n,).
            name (str): Name of data.
            x_labels (str, list of str): Name or names of input dimensions.
            y_label (str): Name of output dimension.

        Examples:
            &gt;&gt;&gt; channel = mogptk.Data([0, 1, 2, 3], [4, 3, 5, 6])
        &#34;&#34;&#34;

        # convert dicts to lists
        if x_labels is not None:
            if isinstance(x_labels, str):
                x_labels = [x_labels]
            if not isinstance(x_labels, list) or not all(isinstance(label, str) for label in x_labels):
                raise ValueError(&#34;x_labels must be a string or list of strings for each input dimension&#34;)

            if isinstance(X, dict):
                it = iter(X.values())
                first = len(next(it))
                if not all(isinstance(x, (list, np.ndarray)) for x in X.values()) or not all(len(x) == first for x in it):
                    raise ValueError(&#34;X dict should contain all lists or np.ndarrays where each has the same length&#34;)
                if not all(key in X for key in x_labels):
                    raise ValueError(&#34;X dict must contain all keys listed in x_labels&#34;)
                X = [X[key] for key in x_labels]

        # check if X is correct
        if isinstance(X, list):
            if all(isinstance(x, list) for x in X):
                m = len(X[0])
                if not all(len(x) == m for x in X[1:]):
                    raise ValueError(&#34;X list items must all be lists of the same length&#34;)
                if not all(all(isinstance(val, (int, float, datetime.datetime, np.datetime64)) for val in x) for x in X):
                    raise ValueError(&#34;X list items must all be lists of numbers or datetime&#34;)
                if not all(_is_homogeneous_type(x) for x in X):
                    raise ValueError(&#34;X list items must all be lists with elements of the same type&#34;)
            elif all(isinstance(x, np.ndarray) for x in X):
                m = len(X[0])
                if not all(len(x) == m for x in X[1:]):
                    raise ValueError(&#34;X list items must all be numpy.ndarrays of the same length&#34;)
            elif not all(isinstance(x, (int, float, datetime.datetime, np.datetime64)) for x in X):
                raise ValueError(&#34;X list items must be all lists, all numpy.ndarrays, or all numbers or datetime&#34;)
            elif not _is_homogeneous_type(X):
                raise ValueError(&#34;X list items must all have elements of the same type&#34;)
            X = [np.array(x) for x in X]
        elif isinstance(X, np.ndarray):
            if X.ndim == 1:
                X = X.reshape(-1, 1)
            if X.ndim != 2:
                raise ValueError(&#34;X must be either a one or two dimensional array of data&#34;)
            X = [X[:,i] for i in range(X.shape[1])]
        else:
            raise ValueError(&#34;X must be list or numpy array, if dict is passed then x_labels must also be set&#34;)

        input_dims = len(X)
        # try to cast unknown data types, X becomes np.float64 or np.datetime64
        for i in range(input_dims):
            if X[i].dtype == np.object_ or np.issubdtype(X[i].dtype, np.character):
                # convert datetime.datetime or strings to np.datetime64
                try:
                    X[i] = X[i].astype(np.datetime64)
                except:
                    raise ValueError(&#34;X data must have a number or datetime data type&#34;)
            elif not np.issubdtype(X[i].dtype, np.datetime64):
                try:
                    X[i] = X[i].astype(np.float64)
                except:
                    raise ValueError(&#34;X data must have a number or datetime data type&#34;)

            # convert X datetime64[us] to a higher unit like s, m, h, D, ...
            if np.issubdtype(X[i].dtype, np.datetime64):
                X[i] = _datetime64_to_higher_unit(X[i])

        # check if Y is correct
        if isinstance(Y, list):
            if not all(isinstance(y, (int, float)) for y in Y):
                raise ValueError(&#34;Y list items must all be numbers&#34;)
            elif not _is_homogeneous_type(Y):
                raise ValueError(&#34;Y list items must all have elements of the same type&#34;)
            Y = np.array(Y)
        elif not isinstance(Y, np.ndarray):
            raise ValueError(&#34;Y must be list or numpy array&#34;)

        # try to cast unknown data types, Y becomes np.float64
        try:
            Y = Y.astype(np.float64)
        except:
            raise ValueError(&#34;Y data must have a number data type&#34;)

        if Y_err is not None:
            # check if Y_err is correct
            if isinstance(Y_err, list):
                if not all(isinstance(y, (int, float)) for y in Y_err):
                    raise ValueError(&#34;Y_err list items must all be numbers&#34;)
                elif not _is_homogeneous_type(Y_err):
                    raise ValueError(&#34;Y_err list items must all have elements of the same type&#34;)
                Y_err = np.array(Y_err)
            elif not isinstance(Y_err, np.ndarray):
                raise ValueError(&#34;Y_err must be list or numpy array&#34;)
            if Y.shape != Y_err.shape:
                raise ValueError(&#34;Y and Y_err must have the same shape&#34;)

            # try to cast unknown data types, Y becomes np.float64
            try:
                Y_err = Y_err.astype(np.float64)
            except:
                raise ValueError(&#34;Y_err data must have a number data type&#34;)

        # convert meshgrids to flat arrays
        if 1 &lt; X[0].ndim and 1 &lt; Y.ndim and X[0].shape == Y.shape:
            X = [np.ravel(x) for x in X]
            Y = np.ravel(Y)
            if Y_err is not None:
                Y_err = np.ravel(Y_err)

        if any(x.ndim != 1 for x in X):
            raise ValueError(&#34;X must be a one dimensional array of data for every input dimension&#34;)
        if Y.ndim != 1:
            raise ValueError(&#34;Y must be a one dimensional array of data&#34;)
        if Y.shape[0] == 0:
            raise ValueError(&#34;X and Y must have a length greater than zero&#34;)
        if any(x.shape[0] != Y.shape[0] for x in X):
            raise ValueError(&#34;X and Y must be of the same length for each input dimension&#34;)


        self.X = [Serie(X[i]) for i in range(input_dims)] # [shape (n)] * input_dims
        self.Y = Serie(Y) # shape (n)
        self.Y_err = None
        if Y_err is not None:
            self.Y_err = Y_err # shape (n)
        self.mask = np.array([True] * Y.shape[0])
        self.F = None
        self.X_pred = None
        self.Y_mu_pred = {}
        self.Y_var_pred = {}
        self.removed_ranges = [[]] * input_dims

        self.X_labels = [&#39;X&#39;] * input_dims
        if 1 &lt; input_dims:
            for i in range(input_dims):
                self.X_labels[i] = &#39;X%d&#39; % (i,)
        if isinstance(x_labels, list) and all(isinstance(item, str) for item in x_labels):
            self.X_labels = x_labels

        self.name = None
        if isinstance(name, str):
            self.name = name
        elif isinstance(y_label, str):
            self.name = y_label

        self.Y_label = &#39;Y&#39;
        if isinstance(y_label, str):
            self.Y_label = y_label

    def __repr__(self):
        df = pd.DataFrame()
        for i in range(len(self.X)):
            df[self.X_labels[i]] = self.X[i]
        df[self.Y_label] = self.Y
        return repr(df)

    def copy(self):
        &#34;&#34;&#34;
        Make a deep copy of `Data`.

        Returns:
            mogptk.data.Data

        Examples:
            &gt;&gt;&gt; other = data.copy()
        &#34;&#34;&#34;
        return copy.deepcopy(self)

    def set_name(self, name):
        &#34;&#34;&#34;
        Set name for data channel.

        Args:
            name (str): Name of data.

        Examples:
            &gt;&gt;&gt; data.set_name(&#39;Channel A&#39;)
        &#34;&#34;&#34;
        self.name = name

    def set_labels(self, x_labels, y_label):
        &#34;&#34;&#34;
        Set axis labels for plots.

        Args:
            x_labels (str, list of str): X data names for each input dimension.
            y_label (str): Y data name for output dimension.

        Examples:
            &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
        &#34;&#34;&#34;
        if isinstance(x_labels, str):
            x_labels = [x_labels]
        elif not isinstance(x_labels, list) or not all(isinstance(item, str) for item in x_labels):
            raise ValueError(&#34;x_labels must be list of strings&#34;)
        if not isinstance(y_label, str):
            raise ValueError(&#34;y_label must be string&#34;)
        if len(x_labels) != self.get_input_dims():
            raise ValueError(&#34;x_labels must have the same input dimensions as the data&#34;)

        self.X_labels = x_labels
        self.Y_label = y_label

    def set_function(self, f):
        &#34;&#34;&#34;
        Set the (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.
    
        The function should take one argument X of shape (n,input_dims) and return Y of shape (n,). If your data has only one input dimension, you can use X[:,0] to select the first (and only) input dimension.

        Args:
            f (function): Function taking X with shape (n,input_dims) and returning shape (n,) as Y.

        Examples:
            &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
        &#34;&#34;&#34;
        _check_function(f, self.get_input_dims(), [x.is_datetime64() for x in self.X])
        self.F = f

    def rescale_x(self, upper=1000.0):
        &#34;&#34;&#34;
        Rescale the X axis so that it is in the interval [0.0,upper]. This helps training most kernels.

        Args:
            upper (float): Upper end of the interval.

        Examples:
            &gt;&gt;&gt; data.rescale_x()
        &#34;&#34;&#34;

        for i in range(self.get_input_dims()):
            X = self.X[i].transformed
            xmin = np.min(X)
            xmax = np.max(X)
            t = TransformLinear(xmin, (xmax-xmin)/upper)
            t.set_data(X)
            self.X[i].apply(t)

    def transform(self, transformer):
        &#34;&#34;&#34;
        Transform the Y axis data by using one of the provided transformers, such as `TransformDetrend`, `TransformLinear`, `TransformLog`, `TransformNormalize`, `TransformStandard`, etc.

        Args:
            transformer (obj): Transformer object derived from TransformBase.

        Examples:
            &gt;&gt;&gt; data.transform(mogptk.TransformDetrend(degree=2))        # remove polynomial trend
            &gt;&gt;&gt; data.transform(mogptk.TransformLinear(slope=1, bias=2))  # remove linear trend
            &gt;&gt;&gt; data.transform(mogptk.TransformLog)                      # log transform the data
            &gt;&gt;&gt; data.transform(mogptk.TransformNormalize)                # transform to [-1,1]
            &gt;&gt;&gt; data.transform(mogptk.TransformStandard)                 # transform to mean=0, var=1
        &#34;&#34;&#34;

        t = transformer
        if isinstance(t, type):
            t = transformer()
        else:
            t = copy.deepcopy(t)
        t.set_data(self)

        self.Y.apply(t, self.X)
    
    def filter(self, start, end, dim=None):
        &#34;&#34;&#34;
        Filter the data range to be between `start` and `end` in the X axis.

        Args:
            start (float, str, list): Start of interval.
            end (float, str, list): End of interval (not included).
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

        Examples:
            &gt;&gt;&gt; data.filter(3, 8)
        
            &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)
        
        if dim is not None:
            ind = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
        else:
            ind = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
            for i in range(1,self.get_input_dims()):
                ind = np.logical_and(ind, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))

        self.X = [x[ind] for x in self.X]
        self.Y = self.Y[ind]
        self.mask = self.mask[ind]

    def aggregate(self, duration, f=np.mean, dim=0):
        &#34;&#34;&#34;
        Aggregate the data by duration and apply a function to obtain a reduced dataset.

        For example, group daily data by week and take the mean. The duration can be set as a number which defined the intervals on the X axis, or by a string written in the duration format in case the X axis has data type `numpy.datetime64`. The duration format uses: Y=year, M=month, W=week, D=day, h=hour, m=minute, and s=second. For example, 3W1D means three weeks and one day, ie. 22 days, or 6M to mean six months.

        Args:
            duration (float, str): Duration along the X axis or as a string in the duration format.
            f (function): Function to use to reduce data mapping a numpy array to a scalar, such as `numpy.mean`.
            dim (int): Input dimension to apply to, defaults to the first input dimension.

        Examples:
            &gt;&gt;&gt; data.aggregate(5)

            &gt;&gt;&gt; data.aggregate(&#39;2W&#39;, f=np.sum)
        &#34;&#34;&#34;
        start = np.min(self.X[dim])
        end = np.max(self.X[dim])
        step = _parse_delta(duration)

        X = np.arange(start+step/2, end+step/2, step)
        Y = np.empty((len(X)))
        for i in range(len(X)):
            ind = (self.X[dim] &gt;= X[i]-step/2) &amp; (self.X[dim] &lt; X[i]+step/2)
            Y[i] = f(self.Y[ind])

        self.X[dim] = Serie(X, self.X[dim].transformers)
        self.Y = Serie(Y, self.Y.transformers, self.X)
        self.mask = np.array([True] * len(self.Y))

    ################################################################

    def get_name(self):
        &#34;&#34;&#34;
        Return the name of the channel.

        Returns:
            str

        Examples:
            &gt;&gt;&gt; data.get_name()
            &#39;A&#39;
        &#34;&#34;&#34;
        return self.name

    def has_test_data(self):
        &#34;&#34;&#34;
        Returns True if observations have been removed using the `remove_*` methods.

        Returns:
            boolean

        Examples:
            &gt;&gt;&gt; data.has_test_data()
            True
        &#34;&#34;&#34;
        return False in self.mask

    def get_input_dims(self):
        &#34;&#34;&#34;
        Returns the number of input dimensions.

        Returns:
            int: Number of input dimensions.

        Examples:
            &gt;&gt;&gt; data.get_input_dims()
            2
        &#34;&#34;&#34;
        return len(self.X)
    
    def get_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns all observations, train and test.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_data()
        &#34;&#34;&#34;
        if transformed:
            return self.X, self.Y.transformed
        return self.X, np.array(self.Y)

    def get_train_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns the observations used for training.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_train_data()
        &#34;&#34;&#34;
        if transformed:
            return [x[self.mask] for x in self.X], self.Y.transformed[self.mask]
        return [x[self.mask] for x in self.X], np.array(self.Y[self.mask])

    def get_test_data(self, transformed=False):
        &#34;&#34;&#34;
        Returns the observations used for testing which correspond to the removed points.

        Arguments:
            transformed (boolean): Return transformed data.

        Returns:
            list of numpy.ndarray: X data of shape [(n,)] * input_dims.
            numpy.ndarray: Y data of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y = data.get_test_data()
        &#34;&#34;&#34;
        X = [x[~self.mask] for x in self.X]
        if self.F is not None:
            if X[0].shape[0] == 0:
                X, _ = self.get_data()
            Y = self.F(*X)
            if transformed:
                Y = self.Y.transform(Y, X)
            return X, Y
        if transformed:
            return X, self.Y.transformed[~self.mask]
        return X, np.array(self.Y[~self.mask])

    ################################################################

    def reset(self):
        &#34;&#34;&#34;
        Reset the data set and undo the removal of data points. That is, this reverts any calls to `remove_randomly`, `remove_range`, `remove_relative_range`, `remove_random_ranges`, and `remove_index`.
        &#34;&#34;&#34;
        self.mask[:] = True
        for i in range(len(self.removed_ranges)):
            self.removed_ranges[i] = []
    
    def remove_randomly(self, n=None, pct=None):
        &#34;&#34;&#34;
        Removes observations randomly on the whole range. Either `n` observations are removed, or a percentage of the observations.

        Args:
            n (int): Number of observations to remove randomly.
            pct (float): Percentage in interval [0,1] of observations to remove randomly.

        Examples:
            &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

            &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
        &#34;&#34;&#34;
        if n is None:
            if pct is None:
                n = 0
            else:
                n = int(pct * len(self.Y))

        idx = np.random.choice(len(self.Y), n, replace=False)
        self.mask[idx] = False
    
    def remove_range(self, start=None, end=None, dim=None):
        &#34;&#34;&#34;
        Removes observations in the interval `[start,end]`.
        
        Args:
            start (float, str): Start of interval. Defaults to the first value in observations.
            end (float, str): End of interval (not included). Defaults to the last value in observations.
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

        Examples:
            &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.remove_range(3, 8)
        
            &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
            &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if start is None:
            start = [np.min(x) for x in self.X]
        if end is None:
            end = [np.max(x) for x in self.X]

        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)

        if dim is not None:
            mask = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
            self.removed_ranges[dim].append([start[dim], end[dim]])
        else:
            mask = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
            for i in range(1,self.get_input_dims()):
                mask = np.logical_or(mask, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))
            for i in range(self.get_input_dims()):
                self.removed_ranges[i].append([start[i], end[i]])
        self.mask[np.where(mask)] = False
    
    def remove_relative_range(self, start=0.0, end=1.0, dim=None):
        &#34;&#34;&#34;
        Removes observations between `start` and `end` as a percentage of the number of observations. So `0` is the first observation, `0.5` is the middle observation, and `1` is the last observation.

        Args:
            start (float): Start percentage in interval [0,1].
            end (float): End percentage in interval [0,1].
            dim (int): Input dimension to apply to, if not specified applies to all input dimensions.
        &#34;&#34;&#34;
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)

        x_min = [np.min(x) for x in self.X]
        x_max = [np.max(x) for x in self.X]
        for i in range(self.get_input_dims()):
            start[i] = x_min[i] + max(0.0, min(1.0, start[i])) * (x_max[i]-x_min[i])
            end[i] = x_min[i] + max(0.0, min(1.0, end[i])) * (x_max[i]-x_min[i])

        self.remove_range(start, end, dim)

    def remove_random_ranges(self, n, duration, dim=0):
        &#34;&#34;&#34;
        Removes a number of ranges to simulate sensor failure. May remove fewer ranges if there is no more room to remove a range in the remaining data.

        Args:
            n (int): Number of ranges to remove.
            duration (float, str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).
            dim (int): Input dimension to apply to, defaults to the first input dimension.

        Examples:
            &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

            &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
        &#34;&#34;&#34;
        if n &lt; 1:
            return

        delta = _parse_delta(duration)
        m = (np.max(self.X[dim])-np.min(self.X[dim])) - n*delta
        if m &lt;= 0:
            raise ValueError(&#34;no data left after removing ranges&#34;)

        locs = self.X[dim] &lt;= (np.max(self.X[dim])-delta)
        locs[sum(locs)] = True # make sure the last data point can be deleted
        for i in range(n):
            if len(self.X[dim][locs]) == 0:
                break # range could not be removed, there is no remaining data range of width delta
            x = self.X[dim][locs][np.random.randint(len(self.X[dim][locs]))]
            locs[(self.X[dim] &gt; x-delta) &amp; (self.X[dim] &lt; x+delta)] = False
            self.mask[(self.X[dim] &gt;= x) &amp; (self.X[dim] &lt; x+delta)] = False
            self.removed_ranges[dim].append([x, x+delta])

    def remove_index(self, index):
        &#34;&#34;&#34;
        Removes observations of given index

        Args:
            index(list, numpy.ndarray): Array of indexes of the data to remove.
        &#34;&#34;&#34;
        if isinstance(index, list):
            index = np.array(index)
        elif not isinstance(index, np.ndarray):
            raise ValueError(&#34;index must be list or numpy array&#34;)

        self.mask[index] = False
    
    ################################################################
    
    def get_prediction_names(self):
        &#34;&#34;&#34;
        Returns the model names of the saved predictions.

        Returns:
            list: List of prediction names.

        Examples:
            &gt;&gt;&gt; data.get_prediction_names()
            [&#39;MOSM&#39;, &#39;CSM&#39;, &#39;SM-LMC&#39;, &#39;CONV&#39;]
        &#34;&#34;&#34;
        return self.Y_mu_pred.keys()
    
    def get_prediction_x(self):
        &#34;&#34;&#34;
        Returns the prediction X range.

        Returns:
            numpy.ndarray: X prediction of shape [(n,)] * input_dims.

        Examples:
            &gt;&gt;&gt; x = data.get_prediction_x()
        &#34;&#34;&#34;
        if self.X_pred is None:
            return self.X.copy()
        return self.X_pred.copy()
    
    def get_prediction(self, name, sigma=2.0, transformed=False):
        &#34;&#34;&#34;
        Returns the prediction of a given name with a confidence interval of `sigma` times the standard deviation.

        Args:
            name (str): Name of the model of the prediction.
            sigma (float): The confidence interval&#39;s number of standard deviations.
            transformed (boolean): Return transformed data as used for training.

        Returns:
            numpy.ndarray: X prediction of shape [(n,)] * input_dims.
            numpy.ndarray: Y mean prediction of shape (n,).
            numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
            numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

        Examples:
            &gt;&gt;&gt; x, y_mean, y_var_lower, y_var_upper = data.get_prediction(&#39;MOSM&#39;, sigma=1)
        &#34;&#34;&#34;
        if name not in self.Y_mu_pred:
            raise ValueError(&#34;prediction name &#39;%s&#39; does not exist&#34; % (name))
       
        if self.X_pred is None:
            X = self.X.copy()
        else:
            X = self.X_pred.copy()
        mu = self.Y_mu_pred[name]
        lower = mu - sigma*np.sqrt(self.Y_var_pred[name])
        upper = mu + sigma*np.sqrt(self.Y_var_pred[name])

        if transformed:
            return X, mu, lower, upper

        mu = Serie(self.Y.detransform(mu, X), self.Y.transformers, transformed=mu)
        lower = Serie(self.Y.detransform(lower, X), self.Y.transformers, transformed=lower)
        upper = Serie(self.Y.detransform(upper, X), self.Y.transformers, transformed=upper)
        return X, mu, lower, upper

    def _format_prediction_x(self, X):
        if isinstance(X, np.ndarray):
            if X.ndim == 1:
                X = X.reshape(-1,1)
            if X.ndim != 2 or X.shape[1] != self.get_input_dims():
                raise ValueError(&#34;X shape must be (n,input_dims) for each channel&#34;)
            X = [X[:,i] for i in range(self.get_input_dims())]
        elif not isinstance(X, list):
            raise ValueError(&#34;X expected to be a list or numpy.ndarray for each channel&#34;)
        if not all(x.ndim == 1 for x in X) or len(X) != self.get_input_dims():
            raise ValueError(&#34;X shape must be (n,), (n,input_dims), or [(n,)] * input_dims for each channel&#34;)
        X = [X[i].astype(self.X[i].dtype) for i in range(self.get_input_dims())]
        return X

    def set_prediction_x(self, X):
        &#34;&#34;&#34;
        Set the prediction range directly for saved predictions. This will clear old predictions.

        Args:
            X (list, numpy.ndarray): Array of shape (n,), (n,input_dims), or [(n,)] * input_dims used for predictions.

        Examples:
            &gt;&gt;&gt; data.set_prediction_x([5.0, 5.5, 6.0, 6.5, 7.0])
        &#34;&#34;&#34;
        X = self._format_prediction_x(X)
        self.X_pred = [Serie(X[i], self.X[i].transformers) for i in range(self.get_input_dims())]

        # clear old prediction data now that X_pred has been updated
        self.clear_predictions()

    def set_prediction_range(self, start=None, end=None, n=None, step=None):
        &#34;&#34;&#34;
        Sets the prediction range. The interval is set as `[start,end]`, with either `n` points or a given step between the points.

        Args:
            start (float, str, list): Start of interval, defaults to the first observation.
            end (float, str, list): End of interval, defaults to the last observation.
            n (int, list): Number of points to generate in the interval.
            step (float, str, list): Spacing between points in the interval.

            If neither step or n is passed, default number of points is 100.

        Examples:
            &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.set_prediction_range(3, 8, 200)
        
            &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
            &gt;&gt;&gt; data.set_prediction_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1D&#39;)
        &#34;&#34;&#34;
        if start is None:
            start = [x[0] for x in self.X]
        if end is None:
            end = [x[-1] for x in self.X]
        
        start = self._normalize_x_val(start)
        end = self._normalize_x_val(end)
        n = self._normalize_val(n)
        step = self._normalize_val(step)
        for i in range(self.get_input_dims()):
            if n is not None and not isinstance(n[i], int):
                raise ValueError(&#34;n must be integer&#34;)
            if step is not None and np.issubdtype(self.X[i].dtype, np.datetime64):
                step[i] = _parse_delta(step[i])

        if np.any(end &lt;= start):
            raise ValueError(&#34;start must be lower than end&#34;)

        # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
        X_pred = [np.array([])] * self.get_input_dims()
        for i in range(self.get_input_dims()):
            if n is not None and n[i] is not None:
                X_pred[i] = start[i] + (end[i]-start[i])*np.linspace(0.0, 1.0, int(n[i]))
            else:
                if step is None or step[i] is None:
                    x_step = (end[i]-start[i])/100
                else:
                    x_step = _parse_delta(step[i])
                X_pred[i] = np.arange(start[i], end[i]+x_step, x_step)
        self.X_pred = [Serie(x, self.X[i].transformers) for i, x in enumerate(X_pred)]

        # clear old prediction data now that X_pred has been updated
        self.clear_predictions()

    def clear_predictions(self):
        &#34;&#34;&#34;
        Clear all saved predictions.
        &#34;&#34;&#34;
        self.Y_mu_pred = {}
        self.Y_var_pred = {}

    ################################################################

    def get_nyquist_estimation(self):
        &#34;&#34;&#34;
        Estimate the Nyquist frequency by taking 0.5/(minimum distance of points).

        Returns:
            numpy.ndarray: Nyquist frequency array of shape (input_dims,).

        Examples:
            &gt;&gt;&gt; freqs = data.get_nyquist_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        nyquist = np.empty((input_dims,))
        for i in range(self.get_input_dims()):
            x = np.sort(self.X[i].transformed[self.mask])
            dist = np.abs(x[1:]-x[:-1])
            dist = np.min(dist[np.nonzero(dist)])
            nyquist[i] = 0.5/dist
        return nyquist

    def _get_psd_peaks(self, w, psd):
        peaks, _ = signal.find_peaks(psd)
        if len(peaks) == 0:
            return np.array([]), np.array([]), np.array([])
        peaks = peaks[np.argsort(psd[peaks])[::-1]] # sort by biggest peak first

        widths, width_heights, _, _ = signal.peak_widths(psd, peaks, rel_height=0.5)
        widths *= w[1]-w[0]

        positions = w[peaks]
        amplitudes = psd[peaks]
        variances = widths / np.sqrt(8 * np.log(amplitudes / width_heights)) # from full-width half-maximum to Gaussian sigma
        return amplitudes, positions, variances

    def get_lombscargle_estimation(self, Q=1, n=10000):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using Lomb-Scargle.

        Args:
            Q (int): Number of peaks to find.
            n (int): Number of points to use for Lomb-Scargle.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_lombscargle_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # i.e. A is the amplitude or peak height, B the mean or peak position, and C the std.dev. or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
            w = np.linspace(0.0, nyquist[i], n+1)[1:]
            psd = signal.lombscargle(x[:,i]*2.0*np.pi, y, w)

            amplitudes, positions, variances = self._get_psd_peaks(w, psd)
            if len(positions) == 0:
                continue
            if Q &lt; len(amplitudes):
                amplitudes = amplitudes[:Q]
                positions = positions[:Q]
                variances = variances[:Q]

            n = len(amplitudes)
            A[:n,i] = np.sqrt(amplitudes)
            B[:n,i] = positions
            C[:n,i] = variances
        return A, B, C

    def get_bnse_estimation(self, Q=1, n=1000):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using BNSE (Bayesian Non-parametric Spectral Estimation).

        Args:
            Q (int): Number of peaks to find.
            n (int): Number of points of the grid to evaluate frequencies.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_bnse_estimation()
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
            w, psd = BNSE(x[:,i], y, max_freq=nyquist[i], n=n)
            amplitudes, positions, variances = self._get_psd_peaks(w[:,0], psd[:,0])
            if len(positions) == 0:
                continue

            if Q &lt; len(amplitudes):
                amplitudes = amplitudes[:Q]
                positions = positions[:Q]
                variances = variances[:Q]

            num = len(amplitudes)
            # division by 100 makes it similar to other estimators (emperically found) TODO: remove?
            A[:num,i] = np.sqrt(amplitudes) / 100
            B[:num,i] = positions
            C[:num,i] = variances
        return A, B, C

    def get_sm_estimation(self, Q=1, method=&#39;LS&#39;, optimizer=&#39;Adam&#39;, iters=100, params={}, plot=False):
        &#34;&#34;&#34;
        Peak estimation of the spectrum using the spectral mixture kernel.

        Args:
            Q (int): Number of peaks to find.
            method (str): Method of estimating SM kernels.
            optimizer (str): Optimization method for SM kernels.
            iters (str): Maximum iteration for SM kernels.
            params (object): Additional parameters for the PyTorch optimizer.
            plot (bool): Show the PSD of the kernel after fitting.

        Returns:
            numpy.ndarray: Amplitude array of shape (Q,input_dims).
            numpy.ndarray: Frequency array of shape (Q,input_dims).
            numpy.ndarray: Variance array of shape (Q,input_dims).

        Examples:
            &gt;&gt;&gt; amplitudes, means, variances = data.get_sm_estimation()
        &#34;&#34;&#34;
        from .models.sm import SM

        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((Q, input_dims))
        B = np.zeros((Q, input_dims))
        C = np.zeros((Q, input_dims))

        sm = SM(self, Q)
        sm.init_parameters(method)
        sm.train(method=optimizer, iters=iters, **params)

        if plot:
            nyquist = self.get_nyquist_estimation()
            means = np.array([sm.gpr.kernel[0][q].mean.numpy() for q in range(Q)])
            weights = np.array([sm.gpr.kernel[0][q].sigma.numpy()**2 for q in range(Q)])
            scales = np.array([sm.gpr.kernel[0][q].variance.numpy() for q in range(Q)])
            nyquist = np.expand_dims(nyquist, 0)
            means = np.expand_dims(means, 1)
            scales = np.expand_dims(scales, 1)
            plot_spectrum(means, scales, weights=weights, nyquist=nyquist, title=self.name)

        for q in range(Q):
            A[q,:] = sm.gpr.kernel[0][q].sigma.numpy()**2  # TODO: weight is not per input_dims
            B[q,:] = sm.gpr.kernel[0][q].mean.numpy()
            C[q,:] = sm.gpr.kernel[0][q].variance.numpy()
        return A, B, C

    def plot(self, pred=None, title=None, ax=None, legend=True, errorbars=True, transformed=False):
        &#34;&#34;&#34;
        Plot the data including removed observations, latent function, and predictions.

        Args:
            pred (str): Specify model name to draw.
            title (str): Set the title of the plot.
            ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
            legend (boolean): Display legend.
            transformed (boolean): Display transformed Y data as used for training.

        Returns:
            matplotlib.axes.Axes

        Examples:
            &gt;&gt;&gt; ax = data.plot()
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)

        legends = []
        if errorbars and self.Y_err is not None:
            x, y = self.get_train_data(transformed=transformed)
            yl = self.Y[self.mask] - self.Y_err[self.mask]
            yu = self.Y[self.mask] + self.Y_err[self.mask]
            if transformed:
                yl = self.Y.transform(yl, x)
                yu = self.Y.transform(yu, x)
            plt.errorbar(x[0], y, [y-yl, yu-y], elinewidth=0.5, ecolor=&#39;k&#39;, capsize=0, ls=&#39;&#39;, marker=&#39;&#39;)

        colors = list(matplotlib.colors.TABLEAU_COLORS)
        for i, name in enumerate(self.Y_mu_pred):
            if self.Y_mu_pred[name].size != 0 and (pred is None or name.lower() == pred.lower()):
                X_pred, mu, lower, upper = self.get_prediction(name, transformed=transformed)

                idx = np.argsort(X_pred[0])
                ax.plot(X_pred[0][idx], mu[idx], ls=&#39;-&#39;, color=colors[i], lw=2)
                ax.fill_between(X_pred[0][idx], lower[idx], upper[idx], color=colors[i], alpha=0.1)
                #ax.plot(X_pred[:,0][idx], lower[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)
                #ax.plot(X_pred[:,0][idx], upper[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)

                label = &#39;Prediction&#39;
                if name is not None:
                    label += &#39; &#39; + name
                legends.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=colors[i], lw=2, label=label))

        if self.F is not None:
            if self.X_pred is None:
                xmin = np.min(self.X[0])
                xmax = np.max(self.X[0])
            else:
                xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
                xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))

            if np.issubdtype(self.X[0].dtype, np.datetime64):
                dt = np.timedelta64(1,self.X[0].get_time_unit())
                n = int((xmax-xmin) / dt) + 1
                x = np.arange(xmin, xmax+np.timedelta64(1,&#39;us&#39;), dt, dtype=self.X[0].dtype)
            else:
                n = len(self.X[0])*10
                x = np.linspace(xmin, xmax, n)

            x = [x]
            y = self.F(*x)
            if transformed:
                y = self.Y.transform(y, x)

            ax.plot(x[0], y, &#39;r--&#39;, lw=1)
            legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;True&#39;))

        _, Y = self.get_data(transformed=transformed)
        idx = np.argsort(self.X[0])
        ax.plot(self.X[0][idx], Y[idx], &#39;k--&#39;, alpha=0.8)
        legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;k&#39;, label=&#39;All Points&#39;))

        x, y = self.get_train_data(transformed=transformed)
        ax.plot(x[0], y, &#39;k.&#39;, mew=0.5, ms=10, markeredgecolor=&#39;white&#39;)
        legends.append(plt.Line2D([0], [0], ls=&#39;&#39;, color=&#39;k&#39;, marker=&#39;.&#39;, ms=10, label=&#39;Training Points&#39;))

        if self.has_test_data():
            for removed_range in self.removed_ranges[0]:
                x0 = removed_range[0]
                x1 = removed_range[1]
                y0 = ax.get_ylim()[0]
                y1 = ax.get_ylim()[1]
                ax.add_patch(patches.Rectangle(
                    (x0, y0), x1-x0, y1-y0, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.2, lw=0,
                ))
            legends.append(patches.Rectangle(
                (1, 1), 1, 1, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.5, lw=0, label=&#39;Removed Ranges&#39;
            ))

        if self.X_pred is None:
            xmin = np.min(self.X[0])
            xmax = np.max(self.X[0])
        else:
            xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
            xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))
        ax.set_xlim(xmin - (xmax - xmin)*0.001, xmax + (xmax - xmin)*0.001)

        ax.set_xlabel(self.X_labels[0])
        ax.set_ylabel(self.Y_label)
        ax.set_title(self.name if title is None else title, fontsize=14)

        if legend:
            legend_rows = (len(legends)-1)/5 + 1
            ax.legend(handles=legends, loc=&#34;upper center&#34;, bbox_to_anchor=(0.5,(3.0+0.5+0.3*legend_rows)/3.0), ncol=5)

        return ax

    def plot_spectrum(self, title=None, method=&#39;ls&#39;, ax=None, per=None, maxfreq=None, log=False, transformed=True, n=1001):
        &#34;&#34;&#34;
        Plot the spectrum of the data.

        Args:
            title (str): Set the title of the plot.
            method (str): Set the method to get the spectrum such as LS or BNSE.
            ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
            per (str, float, numpy.timedelta64): Set the scale of the X axis depending on the formatter used, eg. per=5, per=&#39;day&#39;, or per=&#39;3D&#39;.
            maxfreq (float): Maximum frequency to plot, otherwise the Nyquist frequency is used.
            log (boolean): Show X and Y axis in log-scale.
            transformed (boolean): Display transformed Y data as used for training.
            n (int): Number of points used for periodogram.

        Returns:
            matplotlib.axes.Axes

        Examples:
            &gt;&gt;&gt; ax = data.plot_spectrum(method=&#39;bnse&#39;)
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

        ax_set = ax is not None
        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)
        
        X_scale = 1.0
        if np.issubdtype(self.X[0].dtype, np.datetime64):
            if per is None:
                per = _datetime64_unit_names[self.X[0].get_time_unit()]
            else:
                unit = _parse_delta(per)
                X_scale = np.timedelta64(1,self.X[0].get_time_unit()) / unit
                if not isinstance(per, str):
                    per = &#39;%s&#39; % (unit,)

        if per is not None:
            ax.set_xlabel(&#39;Frequency [1/&#39;+per+&#39;]&#39;)
        else:
            ax.set_xlabel(&#39;Frequency&#39;)
        
        X = self.X[0].astype(np.float)
        Y = self.Y
        if transformed:
            Y = self.Y.transformed

        idx = np.argsort(X)
        X = X[idx] * X_scale
        Y = Y[idx]

        nyquist = maxfreq
        if nyquist is None:
            dist = np.abs(X[1:]-X[:-1])
            nyquist = float(0.5 / np.average(dist))

        if method.lower() == &#39;ls&#39;:
            X_freq = np.linspace(0.0, nyquist, n)[1:]
            Y_freq = signal.lombscargle(X*2.0*np.pi, Y, X_freq, normalize=True)
        elif method.lower() == &#39;bnse&#39;:
            X_freq, Y_freq = BNSE(np.array(X), np.array(Y), max_freq=nyquist, n=n)
        else:
            raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

        # TODO: normalize periodograms
        # normalize
        #Y_freq /= Y_freq.sum() * (X_freq[1]-X_freq[0])

        ax.plot(X_freq, Y_freq, &#39;-&#39;, c=&#39;k&#39;, lw=2)
        #if len(Y_freq_err) != 0:
        #    ax.fill_between(X_freq, Y_freq-Y_freq_err, Y_freq+Y_freq_err, alpha=0.4)
        ax.set_title((self.name + &#39; Spectrum&#39; if self.name is not None else &#39;&#39;) if title is None else title, fontsize=14)

        if log:
            ax.set_xscale(&#39;log&#39;)
            ax.set_yscale(&#39;log&#39;)

        if not ax_set:
            xmin = X_freq.min()
            xmax = X_freq.max()
            ax.set_xlim(xmin - (xmax - xmin)*0.005, xmax + (xmax - xmin)*0.005)
            ax.set_yticks([])
            ax.set_ylim(0, None)
        return ax

    def _normalize_val(self, val):
        # normalize input values, that is: expand to input_dims if a single value
        if val is None:
            return val
        if isinstance(val, np.ndarray):
            if val.ndim == 0:
                val = [val.item()]
            else:
                val = list(val)
        elif _is_iterable(val):
            val = list(val)
        else:
            val = [val] * self.get_input_dims()
        if len(val) != self.get_input_dims():
            raise ValueError(&#34;value must be a scalar or a list of values for each input dimension&#34;)
        return val

    def _normalize_x_val(self, val):
        # normalize input values for X axis, that is: expand to input_dims if a single value, convert values to appropriate dtype
        val = self._normalize_val(val)
        for i in range(self.get_input_dims()):
            try:
                val[i] = self.X[i].dtype.type(val[i])
            except:
                raise ValueError(&#34;value must be of type %s&#34; % (self.X[i].dtype,))
        return val</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mogptk.data.Data.aggregate"><code class="name flex">
<span>def <span class="ident">aggregate</span></span>(<span>self, duration, f=&lt;function mean&gt;, dim=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the data by duration and apply a function to obtain a reduced dataset.</p>
<p>For example, group daily data by week and take the mean. The duration can be set as a number which defined the intervals on the X axis, or by a string written in the duration format in case the X axis has data type <code>numpy.datetime64</code>. The duration format uses: Y=year, M=month, W=week, D=day, h=hour, m=minute, and s=second. For example, 3W1D means three weeks and one day, ie. 22 days, or 6M to mean six months.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>duration</code></strong> :&ensp;<code>float, str</code></dt>
<dd>Duration along the X axis or as a string in the duration format.</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code></dt>
<dd>Function to use to reduce data mapping a numpy array to a scalar, such as <code>numpy.mean</code>.</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Input dimension to apply to, defaults to the first input dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.aggregate(5)
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.aggregate('2W', f=np.sum)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L451-L479" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def aggregate(self, duration, f=np.mean, dim=0):
    &#34;&#34;&#34;
    Aggregate the data by duration and apply a function to obtain a reduced dataset.

    For example, group daily data by week and take the mean. The duration can be set as a number which defined the intervals on the X axis, or by a string written in the duration format in case the X axis has data type `numpy.datetime64`. The duration format uses: Y=year, M=month, W=week, D=day, h=hour, m=minute, and s=second. For example, 3W1D means three weeks and one day, ie. 22 days, or 6M to mean six months.

    Args:
        duration (float, str): Duration along the X axis or as a string in the duration format.
        f (function): Function to use to reduce data mapping a numpy array to a scalar, such as `numpy.mean`.
        dim (int): Input dimension to apply to, defaults to the first input dimension.

    Examples:
        &gt;&gt;&gt; data.aggregate(5)

        &gt;&gt;&gt; data.aggregate(&#39;2W&#39;, f=np.sum)
    &#34;&#34;&#34;
    start = np.min(self.X[dim])
    end = np.max(self.X[dim])
    step = _parse_delta(duration)

    X = np.arange(start+step/2, end+step/2, step)
    Y = np.empty((len(X)))
    for i in range(len(X)):
        ind = (self.X[dim] &gt;= X[i]-step/2) &amp; (self.X[dim] &lt; X[i]+step/2)
        Y[i] = f(self.Y[ind])

    self.X[dim] = Serie(X, self.X[dim].transformers)
    self.Y = Serie(Y, self.Y.transformers, self.X)
    self.mask = np.array([True] * len(self.Y))</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.clear_predictions"><code class="name flex">
<span>def <span class="ident">clear_predictions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Clear all saved predictions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L866-L871" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clear_predictions(self):
    &#34;&#34;&#34;
    Clear all saved predictions.
    &#34;&#34;&#34;
    self.Y_mu_pred = {}
    self.Y_var_pred = {}</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Make a deep copy of <code><a title="mogptk.data.Data" href="#mogptk.data.Data">Data</a></code>.</p>
<h2 id="returns">Returns</h2>
<p>mogptk.data.Data</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; other = data.copy()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L318-L328" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;
    Make a deep copy of `Data`.

    Returns:
        mogptk.data.Data

    Examples:
        &gt;&gt;&gt; other = data.copy()
    &#34;&#34;&#34;
    return copy.deepcopy(self)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, start, end, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Filter the data range to be between <code>start</code> and <code>end</code> in the X axis.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float, str, list</code></dt>
<dd>Start of interval.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float, str, list</code></dt>
<dd>End of interval (not included).</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Input dimension to apply to, if not specified applies to all input dimensions.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.filter(3, 8)
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.filter('2016-01-15', '2016-06-15')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L423-L449" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def filter(self, start, end, dim=None):
    &#34;&#34;&#34;
    Filter the data range to be between `start` and `end` in the X axis.

    Args:
        start (float, str, list): Start of interval.
        end (float, str, list): End of interval (not included).
        dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

    Examples:
        &gt;&gt;&gt; data.filter(3, 8)
    
        &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
    &#34;&#34;&#34;
    start = self._normalize_x_val(start)
    end = self._normalize_x_val(end)
    
    if dim is not None:
        ind = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
    else:
        ind = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
        for i in range(1,self.get_input_dims()):
            ind = np.logical_and(ind, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))

    self.X = [x[ind] for x in self.X]
    self.Y = self.Y[ind]
    self.mask = self.mask[ind]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_bnse_estimation"><code class="name flex">
<span>def <span class="ident">get_bnse_estimation</span></span>(<span>self, Q=1, n=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Peak estimation of the spectrum using BNSE (Bayesian Non-parametric Spectral Estimation).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Q</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks to find.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points of the grid to evaluate frequencies.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Amplitude array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Frequency array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Variance array of shape (Q,input_dims).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; amplitudes, means, variances = data.get_bnse_estimation()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L953-L995" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_bnse_estimation(self, Q=1, n=1000):
    &#34;&#34;&#34;
    Peak estimation of the spectrum using BNSE (Bayesian Non-parametric Spectral Estimation).

    Args:
        Q (int): Number of peaks to find.
        n (int): Number of points of the grid to evaluate frequencies.

    Returns:
        numpy.ndarray: Amplitude array of shape (Q,input_dims).
        numpy.ndarray: Frequency array of shape (Q,input_dims).
        numpy.ndarray: Variance array of shape (Q,input_dims).

    Examples:
        &gt;&gt;&gt; amplitudes, means, variances = data.get_bnse_estimation()
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
    # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
    A = np.zeros((Q, input_dims))
    B = np.zeros((Q, input_dims))
    C = np.zeros((Q, input_dims))

    nyquist = self.get_nyquist_estimation()
    for i in range(input_dims):
        x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
        w, psd = BNSE(x[:,i], y, max_freq=nyquist[i], n=n)
        amplitudes, positions, variances = self._get_psd_peaks(w[:,0], psd[:,0])
        if len(positions) == 0:
            continue

        if Q &lt; len(amplitudes):
            amplitudes = amplitudes[:Q]
            positions = positions[:Q]
            variances = variances[:Q]

        num = len(amplitudes)
        # division by 100 makes it similar to other estimators (emperically found) TODO: remove?
        A[:num,i] = np.sqrt(amplitudes) / 100
        B[:num,i] = positions
        C[:num,i] = variances
    return A, B, C</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, transformed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns all observations, train and test.</p>
<h2 id="arguments">Arguments</h2>
<p>transformed (boolean): Return transformed data.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>numpy.ndarray</code></dt>
<dd>X data of shape [(n,)] * input_dims.</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y data of shape (n,).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y = data.get_data()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L522-L538" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_data(self, transformed=False):
    &#34;&#34;&#34;
    Returns all observations, train and test.

    Arguments:
        transformed (boolean): Return transformed data.

    Returns:
        list of numpy.ndarray: X data of shape [(n,)] * input_dims.
        numpy.ndarray: Y data of shape (n,).

    Examples:
        &gt;&gt;&gt; x, y = data.get_data()
    &#34;&#34;&#34;
    if transformed:
        return self.X, self.Y.transformed
    return self.X, np.array(self.Y)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_input_dims"><code class="name flex">
<span>def <span class="ident">get_input_dims</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the number of input dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of input dimensions.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.get_input_dims()
2
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L509-L520" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_input_dims(self):
    &#34;&#34;&#34;
    Returns the number of input dimensions.

    Returns:
        int: Number of input dimensions.

    Examples:
        &gt;&gt;&gt; data.get_input_dims()
        2
    &#34;&#34;&#34;
    return len(self.X)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_lombscargle_estimation"><code class="name flex">
<span>def <span class="ident">get_lombscargle_estimation</span></span>(<span>self, Q=1, n=10000)</span>
</code></dt>
<dd>
<div class="desc"><p>Peak estimation of the spectrum using Lomb-Scargle.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Q</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks to find.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points to use for Lomb-Scargle.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Amplitude array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Frequency array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Variance array of shape (Q,input_dims).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; amplitudes, means, variances = data.get_lombscargle_estimation()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L909-L951" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_lombscargle_estimation(self, Q=1, n=10000):
    &#34;&#34;&#34;
    Peak estimation of the spectrum using Lomb-Scargle.

    Args:
        Q (int): Number of peaks to find.
        n (int): Number of points to use for Lomb-Scargle.

    Returns:
        numpy.ndarray: Amplitude array of shape (Q,input_dims).
        numpy.ndarray: Frequency array of shape (Q,input_dims).
        numpy.ndarray: Variance array of shape (Q,input_dims).

    Examples:
        &gt;&gt;&gt; amplitudes, means, variances = data.get_lombscargle_estimation()
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
    # i.e. A is the amplitude or peak height, B the mean or peak position, and C the std.dev. or peak width
    A = np.zeros((Q, input_dims))
    B = np.zeros((Q, input_dims))
    C = np.zeros((Q, input_dims))

    nyquist = self.get_nyquist_estimation()
    for i in range(input_dims):
        x, y = np.array([x.transformed[self.mask] for x in self.X]).T, self.Y.transformed[self.mask]
        w = np.linspace(0.0, nyquist[i], n+1)[1:]
        psd = signal.lombscargle(x[:,i]*2.0*np.pi, y, w)

        amplitudes, positions, variances = self._get_psd_peaks(w, psd)
        if len(positions) == 0:
            continue
        if Q &lt; len(amplitudes):
            amplitudes = amplitudes[:Q]
            positions = positions[:Q]
            variances = variances[:Q]

        n = len(amplitudes)
        A[:n,i] = np.sqrt(amplitudes)
        B[:n,i] = positions
        C[:n,i] = variances
    return A, B, C</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_name"><code class="name flex">
<span>def <span class="ident">get_name</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the name of the channel.</p>
<h2 id="returns">Returns</h2>
<p>str</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.get_name()
'A'
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L483-L494" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_name(self):
    &#34;&#34;&#34;
    Return the name of the channel.

    Returns:
        str

    Examples:
        &gt;&gt;&gt; data.get_name()
        &#39;A&#39;
    &#34;&#34;&#34;
    return self.name</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_nyquist_estimation"><code class="name flex">
<span>def <span class="ident">get_nyquist_estimation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate the Nyquist frequency by taking 0.5/(minimum distance of points).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Nyquist frequency array of shape (input_dims,).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; freqs = data.get_nyquist_estimation()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L875-L893" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_nyquist_estimation(self):
    &#34;&#34;&#34;
    Estimate the Nyquist frequency by taking 0.5/(minimum distance of points).

    Returns:
        numpy.ndarray: Nyquist frequency array of shape (input_dims,).

    Examples:
        &gt;&gt;&gt; freqs = data.get_nyquist_estimation()
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    nyquist = np.empty((input_dims,))
    for i in range(self.get_input_dims()):
        x = np.sort(self.X[i].transformed[self.mask])
        dist = np.abs(x[1:]-x[:-1])
        dist = np.min(dist[np.nonzero(dist)])
        nyquist[i] = 0.5/dist
    return nyquist</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_prediction"><code class="name flex">
<span>def <span class="ident">get_prediction</span></span>(<span>self, name, sigma=2.0, transformed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the prediction of a given name with a confidence interval of <code>sigma</code> times the standard deviation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the model of the prediction.</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code></dt>
<dd>The confidence interval's number of standard deviations.</dd>
<dt><strong><code>transformed</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Return transformed data as used for training.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>X prediction of shape [(n,)] * input_dims.</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y mean prediction of shape (n,).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y lower prediction of uncertainty interval of shape (n,).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y upper prediction of uncertainty interval of shape (n,).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y_mean, y_var_lower, y_var_upper = data.get_prediction('MOSM', sigma=1)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L746-L781" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_prediction(self, name, sigma=2.0, transformed=False):
    &#34;&#34;&#34;
    Returns the prediction of a given name with a confidence interval of `sigma` times the standard deviation.

    Args:
        name (str): Name of the model of the prediction.
        sigma (float): The confidence interval&#39;s number of standard deviations.
        transformed (boolean): Return transformed data as used for training.

    Returns:
        numpy.ndarray: X prediction of shape [(n,)] * input_dims.
        numpy.ndarray: Y mean prediction of shape (n,).
        numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
        numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

    Examples:
        &gt;&gt;&gt; x, y_mean, y_var_lower, y_var_upper = data.get_prediction(&#39;MOSM&#39;, sigma=1)
    &#34;&#34;&#34;
    if name not in self.Y_mu_pred:
        raise ValueError(&#34;prediction name &#39;%s&#39; does not exist&#34; % (name))
   
    if self.X_pred is None:
        X = self.X.copy()
    else:
        X = self.X_pred.copy()
    mu = self.Y_mu_pred[name]
    lower = mu - sigma*np.sqrt(self.Y_var_pred[name])
    upper = mu + sigma*np.sqrt(self.Y_var_pred[name])

    if transformed:
        return X, mu, lower, upper

    mu = Serie(self.Y.detransform(mu, X), self.Y.transformers, transformed=mu)
    lower = Serie(self.Y.detransform(lower, X), self.Y.transformers, transformed=lower)
    upper = Serie(self.Y.detransform(upper, X), self.Y.transformers, transformed=upper)
    return X, mu, lower, upper</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_prediction_names"><code class="name flex">
<span>def <span class="ident">get_prediction_names</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the model names of the saved predictions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>List of prediction names.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.get_prediction_names()
['MOSM', 'CSM', 'SM-LMC', 'CONV']
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L719-L730" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_prediction_names(self):
    &#34;&#34;&#34;
    Returns the model names of the saved predictions.

    Returns:
        list: List of prediction names.

    Examples:
        &gt;&gt;&gt; data.get_prediction_names()
        [&#39;MOSM&#39;, &#39;CSM&#39;, &#39;SM-LMC&#39;, &#39;CONV&#39;]
    &#34;&#34;&#34;
    return self.Y_mu_pred.keys()</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_prediction_x"><code class="name flex">
<span>def <span class="ident">get_prediction_x</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the prediction X range.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>X prediction of shape [(n,)] * input_dims.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; x = data.get_prediction_x()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L732-L744" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_prediction_x(self):
    &#34;&#34;&#34;
    Returns the prediction X range.

    Returns:
        numpy.ndarray: X prediction of shape [(n,)] * input_dims.

    Examples:
        &gt;&gt;&gt; x = data.get_prediction_x()
    &#34;&#34;&#34;
    if self.X_pred is None:
        return self.X.copy()
    return self.X_pred.copy()</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_sm_estimation"><code class="name flex">
<span>def <span class="ident">get_sm_estimation</span></span>(<span>self, Q=1, method='LS', optimizer='Adam', iters=100, params={}, plot=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Peak estimation of the spectrum using the spectral mixture kernel.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Q</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks to find.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Method of estimating SM kernels.</dd>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>str</code></dt>
<dd>Optimization method for SM kernels.</dd>
<dt><strong><code>iters</code></strong> :&ensp;<code>str</code></dt>
<dd>Maximum iteration for SM kernels.</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>object</code></dt>
<dd>Additional parameters for the PyTorch optimizer.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>Show the PSD of the kernel after fitting.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Amplitude array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Frequency array of shape (Q,input_dims).</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Variance array of shape (Q,input_dims).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; amplitudes, means, variances = data.get_sm_estimation()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L997-L1045" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_sm_estimation(self, Q=1, method=&#39;LS&#39;, optimizer=&#39;Adam&#39;, iters=100, params={}, plot=False):
    &#34;&#34;&#34;
    Peak estimation of the spectrum using the spectral mixture kernel.

    Args:
        Q (int): Number of peaks to find.
        method (str): Method of estimating SM kernels.
        optimizer (str): Optimization method for SM kernels.
        iters (str): Maximum iteration for SM kernels.
        params (object): Additional parameters for the PyTorch optimizer.
        plot (bool): Show the PSD of the kernel after fitting.

    Returns:
        numpy.ndarray: Amplitude array of shape (Q,input_dims).
        numpy.ndarray: Frequency array of shape (Q,input_dims).
        numpy.ndarray: Variance array of shape (Q,input_dims).

    Examples:
        &gt;&gt;&gt; amplitudes, means, variances = data.get_sm_estimation()
    &#34;&#34;&#34;
    from .models.sm import SM

    input_dims = self.get_input_dims()

    # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
    # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
    A = np.zeros((Q, input_dims))
    B = np.zeros((Q, input_dims))
    C = np.zeros((Q, input_dims))

    sm = SM(self, Q)
    sm.init_parameters(method)
    sm.train(method=optimizer, iters=iters, **params)

    if plot:
        nyquist = self.get_nyquist_estimation()
        means = np.array([sm.gpr.kernel[0][q].mean.numpy() for q in range(Q)])
        weights = np.array([sm.gpr.kernel[0][q].sigma.numpy()**2 for q in range(Q)])
        scales = np.array([sm.gpr.kernel[0][q].variance.numpy() for q in range(Q)])
        nyquist = np.expand_dims(nyquist, 0)
        means = np.expand_dims(means, 1)
        scales = np.expand_dims(scales, 1)
        plot_spectrum(means, scales, weights=weights, nyquist=nyquist, title=self.name)

    for q in range(Q):
        A[q,:] = sm.gpr.kernel[0][q].sigma.numpy()**2  # TODO: weight is not per input_dims
        B[q,:] = sm.gpr.kernel[0][q].mean.numpy()
        C[q,:] = sm.gpr.kernel[0][q].variance.numpy()
    return A, B, C</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_test_data"><code class="name flex">
<span>def <span class="ident">get_test_data</span></span>(<span>self, transformed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the observations used for testing which correspond to the removed points.</p>
<h2 id="arguments">Arguments</h2>
<p>transformed (boolean): Return transformed data.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>numpy.ndarray</code></dt>
<dd>X data of shape [(n,)] * input_dims.</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y data of shape (n,).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y = data.get_test_data()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L558-L582" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_test_data(self, transformed=False):
    &#34;&#34;&#34;
    Returns the observations used for testing which correspond to the removed points.

    Arguments:
        transformed (boolean): Return transformed data.

    Returns:
        list of numpy.ndarray: X data of shape [(n,)] * input_dims.
        numpy.ndarray: Y data of shape (n,).

    Examples:
        &gt;&gt;&gt; x, y = data.get_test_data()
    &#34;&#34;&#34;
    X = [x[~self.mask] for x in self.X]
    if self.F is not None:
        if X[0].shape[0] == 0:
            X, _ = self.get_data()
        Y = self.F(*X)
        if transformed:
            Y = self.Y.transform(Y, X)
        return X, Y
    if transformed:
        return X, self.Y.transformed[~self.mask]
    return X, np.array(self.Y[~self.mask])</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_train_data"><code class="name flex">
<span>def <span class="ident">get_train_data</span></span>(<span>self, transformed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the observations used for training.</p>
<h2 id="arguments">Arguments</h2>
<p>transformed (boolean): Return transformed data.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>numpy.ndarray</code></dt>
<dd>X data of shape [(n,)] * input_dims.</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>Y data of shape (n,).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y = data.get_train_data()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L540-L556" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_train_data(self, transformed=False):
    &#34;&#34;&#34;
    Returns the observations used for training.

    Arguments:
        transformed (boolean): Return transformed data.

    Returns:
        list of numpy.ndarray: X data of shape [(n,)] * input_dims.
        numpy.ndarray: Y data of shape (n,).

    Examples:
        &gt;&gt;&gt; x, y = data.get_train_data()
    &#34;&#34;&#34;
    if transformed:
        return [x[self.mask] for x in self.X], self.Y.transformed[self.mask]
    return [x[self.mask] for x in self.X], np.array(self.Y[self.mask])</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.has_test_data"><code class="name flex">
<span>def <span class="ident">has_test_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if observations have been removed using the <code>remove_*</code> methods.</p>
<h2 id="returns">Returns</h2>
<p>boolean</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.has_test_data()
True
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L496-L507" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def has_test_data(self):
    &#34;&#34;&#34;
    Returns True if observations have been removed using the `remove_*` methods.

    Returns:
        boolean

    Examples:
        &gt;&gt;&gt; data.has_test_data()
        True
    &#34;&#34;&#34;
    return False in self.mask</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, pred=None, title=None, ax=None, legend=True, errorbars=True, transformed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the data including removed observations, latent function, and predictions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pred</code></strong> :&ensp;<code>str</code></dt>
<dd>Specify model name to draw.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code></dt>
<dd>Set the title of the plot.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes.Axes</code></dt>
<dd>Draw to this axes, otherwise draw to the current axes.</dd>
<dt><strong><code>legend</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Display legend.</dd>
<dt><strong><code>transformed</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Display transformed Y data as used for training.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>matplotlib.axes.Axes</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; ax = data.plot()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L1047-L1161" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, pred=None, title=None, ax=None, legend=True, errorbars=True, transformed=False):
    &#34;&#34;&#34;
    Plot the data including removed observations, latent function, and predictions.

    Args:
        pred (str): Specify model name to draw.
        title (str): Set the title of the plot.
        ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
        legend (boolean): Display legend.
        transformed (boolean): Display transformed Y data as used for training.

    Returns:
        matplotlib.axes.Axes

    Examples:
        &gt;&gt;&gt; ax = data.plot()
    &#34;&#34;&#34;
    # TODO: ability to plot conditional or marginal distribution to reduce input dims
    if self.get_input_dims() &gt; 2:
        raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
    if self.get_input_dims() == 2:
        raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)

    legends = []
    if errorbars and self.Y_err is not None:
        x, y = self.get_train_data(transformed=transformed)
        yl = self.Y[self.mask] - self.Y_err[self.mask]
        yu = self.Y[self.mask] + self.Y_err[self.mask]
        if transformed:
            yl = self.Y.transform(yl, x)
            yu = self.Y.transform(yu, x)
        plt.errorbar(x[0], y, [y-yl, yu-y], elinewidth=0.5, ecolor=&#39;k&#39;, capsize=0, ls=&#39;&#39;, marker=&#39;&#39;)

    colors = list(matplotlib.colors.TABLEAU_COLORS)
    for i, name in enumerate(self.Y_mu_pred):
        if self.Y_mu_pred[name].size != 0 and (pred is None or name.lower() == pred.lower()):
            X_pred, mu, lower, upper = self.get_prediction(name, transformed=transformed)

            idx = np.argsort(X_pred[0])
            ax.plot(X_pred[0][idx], mu[idx], ls=&#39;-&#39;, color=colors[i], lw=2)
            ax.fill_between(X_pred[0][idx], lower[idx], upper[idx], color=colors[i], alpha=0.1)
            #ax.plot(X_pred[:,0][idx], lower[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)
            #ax.plot(X_pred[:,0][idx], upper[idx], ls=&#39;-&#39;, color=colors[i], lw=1, alpha=0.5)

            label = &#39;Prediction&#39;
            if name is not None:
                label += &#39; &#39; + name
            legends.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=colors[i], lw=2, label=label))

    if self.F is not None:
        if self.X_pred is None:
            xmin = np.min(self.X[0])
            xmax = np.max(self.X[0])
        else:
            xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
            xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))

        if np.issubdtype(self.X[0].dtype, np.datetime64):
            dt = np.timedelta64(1,self.X[0].get_time_unit())
            n = int((xmax-xmin) / dt) + 1
            x = np.arange(xmin, xmax+np.timedelta64(1,&#39;us&#39;), dt, dtype=self.X[0].dtype)
        else:
            n = len(self.X[0])*10
            x = np.linspace(xmin, xmax, n)

        x = [x]
        y = self.F(*x)
        if transformed:
            y = self.Y.transform(y, x)

        ax.plot(x[0], y, &#39;r--&#39;, lw=1)
        legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;True&#39;))

    _, Y = self.get_data(transformed=transformed)
    idx = np.argsort(self.X[0])
    ax.plot(self.X[0][idx], Y[idx], &#39;k--&#39;, alpha=0.8)
    legends.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;k&#39;, label=&#39;All Points&#39;))

    x, y = self.get_train_data(transformed=transformed)
    ax.plot(x[0], y, &#39;k.&#39;, mew=0.5, ms=10, markeredgecolor=&#39;white&#39;)
    legends.append(plt.Line2D([0], [0], ls=&#39;&#39;, color=&#39;k&#39;, marker=&#39;.&#39;, ms=10, label=&#39;Training Points&#39;))

    if self.has_test_data():
        for removed_range in self.removed_ranges[0]:
            x0 = removed_range[0]
            x1 = removed_range[1]
            y0 = ax.get_ylim()[0]
            y1 = ax.get_ylim()[1]
            ax.add_patch(patches.Rectangle(
                (x0, y0), x1-x0, y1-y0, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.2, lw=0,
            ))
        legends.append(patches.Rectangle(
            (1, 1), 1, 1, fill=True, color=&#39;xkcd:strawberry&#39;, alpha=0.5, lw=0, label=&#39;Removed Ranges&#39;
        ))

    if self.X_pred is None:
        xmin = np.min(self.X[0])
        xmax = np.max(self.X[0])
    else:
        xmin = min(np.min(self.X[0]), np.min(self.X_pred[0]))
        xmax = max(np.max(self.X[0]), np.max(self.X_pred[0]))
    ax.set_xlim(xmin - (xmax - xmin)*0.001, xmax + (xmax - xmin)*0.001)

    ax.set_xlabel(self.X_labels[0])
    ax.set_ylabel(self.Y_label)
    ax.set_title(self.name if title is None else title, fontsize=14)

    if legend:
        legend_rows = (len(legends)-1)/5 + 1
        ax.legend(handles=legends, loc=&#34;upper center&#34;, bbox_to_anchor=(0.5,(3.0+0.5+0.3*legend_rows)/3.0), ncol=5)

    return ax</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.plot_spectrum"><code class="name flex">
<span>def <span class="ident">plot_spectrum</span></span>(<span>self, title=None, method='ls', ax=None, per=None, maxfreq=None, log=False, transformed=True, n=1001)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the spectrum of the data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code></dt>
<dd>Set the title of the plot.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Set the method to get the spectrum such as LS or BNSE.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes.Axes</code></dt>
<dd>Draw to this axes, otherwise draw to the current axes.</dd>
<dt><strong><code>per</code></strong> :&ensp;<code>str, float, numpy.timedelta64</code></dt>
<dd>Set the scale of the X axis depending on the formatter used, eg. per=5, per='day', or per='3D'.</dd>
<dt><strong><code>maxfreq</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum frequency to plot, otherwise the Nyquist frequency is used.</dd>
<dt><strong><code>log</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Show X and Y axis in log-scale.</dd>
<dt><strong><code>transformed</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Display transformed Y data as used for training.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points used for periodogram.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>matplotlib.axes.Axes</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; ax = data.plot_spectrum(method='bnse')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L1163-L1249" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot_spectrum(self, title=None, method=&#39;ls&#39;, ax=None, per=None, maxfreq=None, log=False, transformed=True, n=1001):
    &#34;&#34;&#34;
    Plot the spectrum of the data.

    Args:
        title (str): Set the title of the plot.
        method (str): Set the method to get the spectrum such as LS or BNSE.
        ax (matplotlib.axes.Axes): Draw to this axes, otherwise draw to the current axes.
        per (str, float, numpy.timedelta64): Set the scale of the X axis depending on the formatter used, eg. per=5, per=&#39;day&#39;, or per=&#39;3D&#39;.
        maxfreq (float): Maximum frequency to plot, otherwise the Nyquist frequency is used.
        log (boolean): Show X and Y axis in log-scale.
        transformed (boolean): Display transformed Y data as used for training.
        n (int): Number of points used for periodogram.

    Returns:
        matplotlib.axes.Axes

    Examples:
        &gt;&gt;&gt; ax = data.plot_spectrum(method=&#39;bnse&#39;)
    &#34;&#34;&#34;
    # TODO: ability to plot conditional or marginal distribution to reduce input dims
    if self.get_input_dims() &gt; 2:
        raise ValueError(&#34;cannot plot more than two input dimensions&#34;)
    if self.get_input_dims() == 2:
        raise NotImplementedError(&#34;two dimensional input data not yet implemented&#34;) # TODO

    ax_set = ax is not None
    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=(12, 3.0), squeeze=True, constrained_layout=True)
    
    X_scale = 1.0
    if np.issubdtype(self.X[0].dtype, np.datetime64):
        if per is None:
            per = _datetime64_unit_names[self.X[0].get_time_unit()]
        else:
            unit = _parse_delta(per)
            X_scale = np.timedelta64(1,self.X[0].get_time_unit()) / unit
            if not isinstance(per, str):
                per = &#39;%s&#39; % (unit,)

    if per is not None:
        ax.set_xlabel(&#39;Frequency [1/&#39;+per+&#39;]&#39;)
    else:
        ax.set_xlabel(&#39;Frequency&#39;)
    
    X = self.X[0].astype(np.float)
    Y = self.Y
    if transformed:
        Y = self.Y.transformed

    idx = np.argsort(X)
    X = X[idx] * X_scale
    Y = Y[idx]

    nyquist = maxfreq
    if nyquist is None:
        dist = np.abs(X[1:]-X[:-1])
        nyquist = float(0.5 / np.average(dist))

    if method.lower() == &#39;ls&#39;:
        X_freq = np.linspace(0.0, nyquist, n)[1:]
        Y_freq = signal.lombscargle(X*2.0*np.pi, Y, X_freq, normalize=True)
    elif method.lower() == &#39;bnse&#39;:
        X_freq, Y_freq = BNSE(np.array(X), np.array(Y), max_freq=nyquist, n=n)
    else:
        raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

    # TODO: normalize periodograms
    # normalize
    #Y_freq /= Y_freq.sum() * (X_freq[1]-X_freq[0])

    ax.plot(X_freq, Y_freq, &#39;-&#39;, c=&#39;k&#39;, lw=2)
    #if len(Y_freq_err) != 0:
    #    ax.fill_between(X_freq, Y_freq-Y_freq_err, Y_freq+Y_freq_err, alpha=0.4)
    ax.set_title((self.name + &#39; Spectrum&#39; if self.name is not None else &#39;&#39;) if title is None else title, fontsize=14)

    if log:
        ax.set_xscale(&#39;log&#39;)
        ax.set_yscale(&#39;log&#39;)

    if not ax_set:
        xmin = X_freq.min()
        xmax = X_freq.max()
        ax.set_xlim(xmin - (xmax - xmin)*0.005, xmax + (xmax - xmin)*0.005)
        ax.set_yticks([])
        ax.set_ylim(0, None)
    return ax</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_index"><code class="name flex">
<span>def <span class="ident">remove_index</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes observations of given index</p>
<h2 id="args">Args</h2>
<p>index(list, numpy.ndarray): Array of indexes of the data to remove.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L703-L715" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def remove_index(self, index):
    &#34;&#34;&#34;
    Removes observations of given index

    Args:
        index(list, numpy.ndarray): Array of indexes of the data to remove.
    &#34;&#34;&#34;
    if isinstance(index, list):
        index = np.array(index)
    elif not isinstance(index, np.ndarray):
        raise ValueError(&#34;index must be list or numpy array&#34;)

    self.mask[index] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_random_ranges"><code class="name flex">
<span>def <span class="ident">remove_random_ranges</span></span>(<span>self, n, duration, dim=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes a number of ranges to simulate sensor failure. May remove fewer ranges if there is no more room to remove a range in the remaining data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of ranges to remove.</dd>
<dt><strong><code>duration</code></strong> :&ensp;<code>float, str</code></dt>
<dd>Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Input dimension to apply to, defaults to the first input dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.remove_random_ranges(3, '1d') # remove three ranges that are 1 day wide
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L671-L701" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def remove_random_ranges(self, n, duration, dim=0):
    &#34;&#34;&#34;
    Removes a number of ranges to simulate sensor failure. May remove fewer ranges if there is no more room to remove a range in the remaining data.

    Args:
        n (int): Number of ranges to remove.
        duration (float, str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).
        dim (int): Input dimension to apply to, defaults to the first input dimension.

    Examples:
        &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

        &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
    &#34;&#34;&#34;
    if n &lt; 1:
        return

    delta = _parse_delta(duration)
    m = (np.max(self.X[dim])-np.min(self.X[dim])) - n*delta
    if m &lt;= 0:
        raise ValueError(&#34;no data left after removing ranges&#34;)

    locs = self.X[dim] &lt;= (np.max(self.X[dim])-delta)
    locs[sum(locs)] = True # make sure the last data point can be deleted
    for i in range(n):
        if len(self.X[dim][locs]) == 0:
            break # range could not be removed, there is no remaining data range of width delta
        x = self.X[dim][locs][np.random.randint(len(self.X[dim][locs]))]
        locs[(self.X[dim] &gt; x-delta) &amp; (self.X[dim] &lt; x+delta)] = False
        self.mask[(self.X[dim] &gt;= x) &amp; (self.X[dim] &lt; x+delta)] = False
        self.removed_ranges[dim].append([x, x+delta])</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_randomly"><code class="name flex">
<span>def <span class="ident">remove_randomly</span></span>(<span>self, n=None, pct=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes observations randomly on the whole range. Either <code>n</code> observations are removed, or a percentage of the observations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of observations to remove randomly.</dd>
<dt><strong><code>pct</code></strong> :&ensp;<code>float</code></dt>
<dd>Percentage in interval [0,1] of observations to remove randomly.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L594-L614" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def remove_randomly(self, n=None, pct=None):
    &#34;&#34;&#34;
    Removes observations randomly on the whole range. Either `n` observations are removed, or a percentage of the observations.

    Args:
        n (int): Number of observations to remove randomly.
        pct (float): Percentage in interval [0,1] of observations to remove randomly.

    Examples:
        &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

        &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
    &#34;&#34;&#34;
    if n is None:
        if pct is None:
            n = 0
        else:
            n = int(pct * len(self.Y))

    idx = np.random.choice(len(self.Y), n, replace=False)
    self.mask[idx] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_range"><code class="name flex">
<span>def <span class="ident">remove_range</span></span>(<span>self, start=None, end=None, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes observations in the interval <code>[start,end]</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float, str</code></dt>
<dd>Start of interval. Defaults to the first value in observations.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float, str</code></dt>
<dd>End of interval (not included). Defaults to the last value in observations.</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Input dimension to apply to, if not specified applies to all input dimensions.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&gt;&gt;&gt; data.remove_range(3, 8)
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data = mogptk.LoadCSV('gold.csv', 'Date', 'Price')
&gt;&gt;&gt; data.remove_range('2016-01-15', '2016-06-15')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L616-L649" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def remove_range(self, start=None, end=None, dim=None):
    &#34;&#34;&#34;
    Removes observations in the interval `[start,end]`.
    
    Args:
        start (float, str): Start of interval. Defaults to the first value in observations.
        end (float, str): End of interval (not included). Defaults to the last value in observations.
        dim (int): Input dimension to apply to, if not specified applies to all input dimensions.

    Examples:
        &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &gt;&gt;&gt; data.remove_range(3, 8)
    
        &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
        &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
    &#34;&#34;&#34;
    if start is None:
        start = [np.min(x) for x in self.X]
    if end is None:
        end = [np.max(x) for x in self.X]

    start = self._normalize_x_val(start)
    end = self._normalize_x_val(end)

    if dim is not None:
        mask = np.logical_and(self.X[dim] &gt;= start[dim], self.X[dim] &lt; end[dim])
        self.removed_ranges[dim].append([start[dim], end[dim]])
    else:
        mask = np.logical_and(self.X[0] &gt;= start[0], self.X[0] &lt; end[0])
        for i in range(1,self.get_input_dims()):
            mask = np.logical_or(mask, np.logical_and(self.X[i] &gt;= start[i], self.X[i] &lt; end[i]))
        for i in range(self.get_input_dims()):
            self.removed_ranges[i].append([start[i], end[i]])
    self.mask[np.where(mask)] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_relative_range"><code class="name flex">
<span>def <span class="ident">remove_relative_range</span></span>(<span>self, start=0.0, end=1.0, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes observations between <code>start</code> and <code>end</code> as a percentage of the number of observations. So <code>0</code> is the first observation, <code>0.5</code> is the middle observation, and <code>1</code> is the last observation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code></dt>
<dd>Start percentage in interval [0,1].</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code></dt>
<dd>End percentage in interval [0,1].</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Input dimension to apply to, if not specified applies to all input dimensions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L651-L669" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def remove_relative_range(self, start=0.0, end=1.0, dim=None):
    &#34;&#34;&#34;
    Removes observations between `start` and `end` as a percentage of the number of observations. So `0` is the first observation, `0.5` is the middle observation, and `1` is the last observation.

    Args:
        start (float): Start percentage in interval [0,1].
        end (float): End percentage in interval [0,1].
        dim (int): Input dimension to apply to, if not specified applies to all input dimensions.
    &#34;&#34;&#34;
    start = self._normalize_x_val(start)
    end = self._normalize_x_val(end)

    x_min = [np.min(x) for x in self.X]
    x_max = [np.max(x) for x in self.X]
    for i in range(self.get_input_dims()):
        start[i] = x_min[i] + max(0.0, min(1.0, start[i])) * (x_max[i]-x_min[i])
        end[i] = x_min[i] + max(0.0, min(1.0, end[i])) * (x_max[i]-x_min[i])

    self.remove_range(start, end, dim)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.rescale_x"><code class="name flex">
<span>def <span class="ident">rescale_x</span></span>(<span>self, upper=1000.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Rescale the X axis so that it is in the interval [0.0,upper]. This helps training most kernels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>upper</code></strong> :&ensp;<code>float</code></dt>
<dd>Upper end of the interval.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.rescale_x()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L380-L397" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rescale_x(self, upper=1000.0):
    &#34;&#34;&#34;
    Rescale the X axis so that it is in the interval [0.0,upper]. This helps training most kernels.

    Args:
        upper (float): Upper end of the interval.

    Examples:
        &gt;&gt;&gt; data.rescale_x()
    &#34;&#34;&#34;

    for i in range(self.get_input_dims()):
        X = self.X[i].transformed
        xmin = np.min(X)
        xmax = np.max(X)
        t = TransformLinear(xmin, (xmax-xmin)/upper)
        t.set_data(X)
        self.X[i].apply(t)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the data set and undo the removal of data points. That is, this reverts any calls to <code>remove_randomly</code>, <code>remove_range</code>, <code>remove_relative_range</code>, <code>remove_random_ranges</code>, and <code>remove_index</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L586-L592" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;
    Reset the data set and undo the removal of data points. That is, this reverts any calls to `remove_randomly`, `remove_range`, `remove_relative_range`, `remove_random_ranges`, and `remove_index`.
    &#34;&#34;&#34;
    self.mask[:] = True
    for i in range(len(self.removed_ranges)):
        self.removed_ranges[i] = []</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_function"><code class="name flex">
<span>def <span class="ident">set_function</span></span>(<span>self, f)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.</p>
<p>The function should take one argument X of shape (n,input_dims) and return Y of shape (n,). If your data has only one input dimension, you can use X[:,0] to select the first (and only) input dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code></dt>
<dd>Function taking X with shape (n,input_dims) and returning shape (n,) as Y.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L365-L378" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_function(self, f):
    &#34;&#34;&#34;
    Set the (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.

    The function should take one argument X of shape (n,input_dims) and return Y of shape (n,). If your data has only one input dimension, you can use X[:,0] to select the first (and only) input dimension.

    Args:
        f (function): Function taking X with shape (n,input_dims) and returning shape (n,) as Y.

    Examples:
        &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
    &#34;&#34;&#34;
    _check_function(f, self.get_input_dims(), [x.is_datetime64() for x in self.X])
    self.F = f</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_labels"><code class="name flex">
<span>def <span class="ident">set_labels</span></span>(<span>self, x_labels, y_label)</span>
</code></dt>
<dd>
<div class="desc"><p>Set axis labels for plots.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_labels</code></strong> :&ensp;<code>str, list</code> of <code>str</code></dt>
<dd>X data names for each input dimension.</dd>
<dt><strong><code>y_label</code></strong> :&ensp;<code>str</code></dt>
<dd>Y data name for output dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.set_labels(['X', 'Y'], 'Cd')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L342-L363" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_labels(self, x_labels, y_label):
    &#34;&#34;&#34;
    Set axis labels for plots.

    Args:
        x_labels (str, list of str): X data names for each input dimension.
        y_label (str): Y data name for output dimension.

    Examples:
        &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
    &#34;&#34;&#34;
    if isinstance(x_labels, str):
        x_labels = [x_labels]
    elif not isinstance(x_labels, list) or not all(isinstance(item, str) for item in x_labels):
        raise ValueError(&#34;x_labels must be list of strings&#34;)
    if not isinstance(y_label, str):
        raise ValueError(&#34;y_label must be string&#34;)
    if len(x_labels) != self.get_input_dims():
        raise ValueError(&#34;x_labels must have the same input dimensions as the data&#34;)

    self.X_labels = x_labels
    self.Y_label = y_label</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_name"><code class="name flex">
<span>def <span class="ident">set_name</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Set name for data channel.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of data.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.set_name('Channel A')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L330-L340" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_name(self, name):
    &#34;&#34;&#34;
    Set name for data channel.

    Args:
        name (str): Name of data.

    Examples:
        &gt;&gt;&gt; data.set_name(&#39;Channel A&#39;)
    &#34;&#34;&#34;
    self.name = name</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_prediction_range"><code class="name flex">
<span>def <span class="ident">set_prediction_range</span></span>(<span>self, start=None, end=None, n=None, step=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the prediction range. The interval is set as <code>[start,end]</code>, with either <code>n</code> points or a given step between the points.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float, str, list</code></dt>
<dd>Start of interval, defaults to the first observation.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float, str, list</code></dt>
<dd>End of interval, defaults to the last observation.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int, list</code></dt>
<dd>Number of points to generate in the interval.</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>float, str, list</code></dt>
<dd>Spacing between points in the interval.</dd>
</dl>
<p>If neither step or n is passed, default number of points is 100.</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&gt;&gt;&gt; data.set_prediction_range(3, 8, 200)
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; data = mogptk.LoadCSV('gold.csv', 'Date', 'Price')
&gt;&gt;&gt; data.set_prediction_range('2016-01-15', '2016-06-15', step='1D')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L813-L864" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_prediction_range(self, start=None, end=None, n=None, step=None):
    &#34;&#34;&#34;
    Sets the prediction range. The interval is set as `[start,end]`, with either `n` points or a given step between the points.

    Args:
        start (float, str, list): Start of interval, defaults to the first observation.
        end (float, str, list): End of interval, defaults to the last observation.
        n (int, list): Number of points to generate in the interval.
        step (float, str, list): Spacing between points in the interval.

        If neither step or n is passed, default number of points is 100.

    Examples:
        &gt;&gt;&gt; data = mogptk.LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &gt;&gt;&gt; data.set_prediction_range(3, 8, 200)
    
        &gt;&gt;&gt; data = mogptk.LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;)
        &gt;&gt;&gt; data.set_prediction_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1D&#39;)
    &#34;&#34;&#34;
    if start is None:
        start = [x[0] for x in self.X]
    if end is None:
        end = [x[-1] for x in self.X]
    
    start = self._normalize_x_val(start)
    end = self._normalize_x_val(end)
    n = self._normalize_val(n)
    step = self._normalize_val(step)
    for i in range(self.get_input_dims()):
        if n is not None and not isinstance(n[i], int):
            raise ValueError(&#34;n must be integer&#34;)
        if step is not None and np.issubdtype(self.X[i].dtype, np.datetime64):
            step[i] = _parse_delta(step[i])

    if np.any(end &lt;= start):
        raise ValueError(&#34;start must be lower than end&#34;)

    # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
    X_pred = [np.array([])] * self.get_input_dims()
    for i in range(self.get_input_dims()):
        if n is not None and n[i] is not None:
            X_pred[i] = start[i] + (end[i]-start[i])*np.linspace(0.0, 1.0, int(n[i]))
        else:
            if step is None or step[i] is None:
                x_step = (end[i]-start[i])/100
            else:
                x_step = _parse_delta(step[i])
            X_pred[i] = np.arange(start[i], end[i]+x_step, x_step)
    self.X_pred = [Serie(x, self.X[i].transformers) for i, x in enumerate(X_pred)]

    # clear old prediction data now that X_pred has been updated
    self.clear_predictions()</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_prediction_x"><code class="name flex">
<span>def <span class="ident">set_prediction_x</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the prediction range directly for saved predictions. This will clear old predictions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list, numpy.ndarray</code></dt>
<dd>Array of shape (n,), (n,input_dims), or [(n,)] * input_dims used for predictions.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.set_prediction_x([5.0, 5.5, 6.0, 6.5, 7.0])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L797-L811" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_prediction_x(self, X):
    &#34;&#34;&#34;
    Set the prediction range directly for saved predictions. This will clear old predictions.

    Args:
        X (list, numpy.ndarray): Array of shape (n,), (n,input_dims), or [(n,)] * input_dims used for predictions.

    Examples:
        &gt;&gt;&gt; data.set_prediction_x([5.0, 5.5, 6.0, 6.5, 7.0])
    &#34;&#34;&#34;
    X = self._format_prediction_x(X)
    self.X_pred = [Serie(X[i], self.X[i].transformers) for i in range(self.get_input_dims())]

    # clear old prediction data now that X_pred has been updated
    self.clear_predictions()</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, transformer)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform the Y axis data by using one of the provided transformers, such as <code>TransformDetrend</code>, <code>TransformLinear</code>, <code>TransformLog</code>, <code>TransformNormalize</code>, <code>TransformStandard</code>, etc.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transformer</code></strong> :&ensp;<code>obj</code></dt>
<dd>Transformer object derived from TransformBase.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; data.transform(mogptk.TransformDetrend(degree=2))        # remove polynomial trend
&gt;&gt;&gt; data.transform(mogptk.TransformLinear(slope=1, bias=2))  # remove linear trend
&gt;&gt;&gt; data.transform(mogptk.TransformLog)                      # log transform the data
&gt;&gt;&gt; data.transform(mogptk.TransformNormalize)                # transform to [-1,1]
&gt;&gt;&gt; data.transform(mogptk.TransformStandard)                 # transform to mean=0, var=1
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/5d611d57e6abfff569d9151118c0d1dd2cc6a99f/mogptk/data.py#L399-L421" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def transform(self, transformer):
    &#34;&#34;&#34;
    Transform the Y axis data by using one of the provided transformers, such as `TransformDetrend`, `TransformLinear`, `TransformLog`, `TransformNormalize`, `TransformStandard`, etc.

    Args:
        transformer (obj): Transformer object derived from TransformBase.

    Examples:
        &gt;&gt;&gt; data.transform(mogptk.TransformDetrend(degree=2))        # remove polynomial trend
        &gt;&gt;&gt; data.transform(mogptk.TransformLinear(slope=1, bias=2))  # remove linear trend
        &gt;&gt;&gt; data.transform(mogptk.TransformLog)                      # log transform the data
        &gt;&gt;&gt; data.transform(mogptk.TransformNormalize)                # transform to [-1,1]
        &gt;&gt;&gt; data.transform(mogptk.TransformStandard)                 # transform to mean=0, var=1
    &#34;&#34;&#34;

    t = transformer
    if isinstance(t, type):
        t = transformer()
    else:
        t = copy.deepcopy(t)
    t.set_data(self)

    self.Y.apply(t, self.X)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mogptk" href="index.html">mogptk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mogptk.data.LoadFunction" href="#mogptk.data.LoadFunction">LoadFunction</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mogptk.data.Data" href="#mogptk.data.Data">Data</a></code></h4>
<ul class="">
<li><code><a title="mogptk.data.Data.aggregate" href="#mogptk.data.Data.aggregate">aggregate</a></code></li>
<li><code><a title="mogptk.data.Data.clear_predictions" href="#mogptk.data.Data.clear_predictions">clear_predictions</a></code></li>
<li><code><a title="mogptk.data.Data.copy" href="#mogptk.data.Data.copy">copy</a></code></li>
<li><code><a title="mogptk.data.Data.filter" href="#mogptk.data.Data.filter">filter</a></code></li>
<li><code><a title="mogptk.data.Data.get_bnse_estimation" href="#mogptk.data.Data.get_bnse_estimation">get_bnse_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_data" href="#mogptk.data.Data.get_data">get_data</a></code></li>
<li><code><a title="mogptk.data.Data.get_input_dims" href="#mogptk.data.Data.get_input_dims">get_input_dims</a></code></li>
<li><code><a title="mogptk.data.Data.get_lombscargle_estimation" href="#mogptk.data.Data.get_lombscargle_estimation">get_lombscargle_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_name" href="#mogptk.data.Data.get_name">get_name</a></code></li>
<li><code><a title="mogptk.data.Data.get_nyquist_estimation" href="#mogptk.data.Data.get_nyquist_estimation">get_nyquist_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_prediction" href="#mogptk.data.Data.get_prediction">get_prediction</a></code></li>
<li><code><a title="mogptk.data.Data.get_prediction_names" href="#mogptk.data.Data.get_prediction_names">get_prediction_names</a></code></li>
<li><code><a title="mogptk.data.Data.get_prediction_x" href="#mogptk.data.Data.get_prediction_x">get_prediction_x</a></code></li>
<li><code><a title="mogptk.data.Data.get_sm_estimation" href="#mogptk.data.Data.get_sm_estimation">get_sm_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_test_data" href="#mogptk.data.Data.get_test_data">get_test_data</a></code></li>
<li><code><a title="mogptk.data.Data.get_train_data" href="#mogptk.data.Data.get_train_data">get_train_data</a></code></li>
<li><code><a title="mogptk.data.Data.has_test_data" href="#mogptk.data.Data.has_test_data">has_test_data</a></code></li>
<li><code><a title="mogptk.data.Data.plot" href="#mogptk.data.Data.plot">plot</a></code></li>
<li><code><a title="mogptk.data.Data.plot_spectrum" href="#mogptk.data.Data.plot_spectrum">plot_spectrum</a></code></li>
<li><code><a title="mogptk.data.Data.remove_index" href="#mogptk.data.Data.remove_index">remove_index</a></code></li>
<li><code><a title="mogptk.data.Data.remove_random_ranges" href="#mogptk.data.Data.remove_random_ranges">remove_random_ranges</a></code></li>
<li><code><a title="mogptk.data.Data.remove_randomly" href="#mogptk.data.Data.remove_randomly">remove_randomly</a></code></li>
<li><code><a title="mogptk.data.Data.remove_range" href="#mogptk.data.Data.remove_range">remove_range</a></code></li>
<li><code><a title="mogptk.data.Data.remove_relative_range" href="#mogptk.data.Data.remove_relative_range">remove_relative_range</a></code></li>
<li><code><a title="mogptk.data.Data.rescale_x" href="#mogptk.data.Data.rescale_x">rescale_x</a></code></li>
<li><code><a title="mogptk.data.Data.reset" href="#mogptk.data.Data.reset">reset</a></code></li>
<li><code><a title="mogptk.data.Data.set_function" href="#mogptk.data.Data.set_function">set_function</a></code></li>
<li><code><a title="mogptk.data.Data.set_labels" href="#mogptk.data.Data.set_labels">set_labels</a></code></li>
<li><code><a title="mogptk.data.Data.set_name" href="#mogptk.data.Data.set_name">set_name</a></code></li>
<li><code><a title="mogptk.data.Data.set_prediction_range" href="#mogptk.data.Data.set_prediction_range">set_prediction_range</a></code></li>
<li><code><a title="mogptk.data.Data.set_prediction_x" href="#mogptk.data.Data.set_prediction_x">set_prediction_x</a></code></li>
<li><code><a title="mogptk.data.Data.transform" href="#mogptk.data.Data.transform">transform</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>